<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>単一リージョンの複数 GKE クラスタと Anthos Service Mesh でマルチクラスタメッシュ環境を構築してみた | クラウドCoEの何でも屋</title><meta name=keywords content="Google Cloud,Google Kubernetes Engine(GKE),Anthos Service Mesh,Kubernetes,Istio"><meta name=description content="はじめに みなさん、こんにちは。今回は単一リージョンに展開した複数 GKE クラスタを単一の Anthos Service Mesh 環境に追加し、GKE クラスタ間で負荷分散を行う方法についてご紹介していきたいと思います。
複数 GKE クラスタでマルチクラスタメッシュを構築することにより、片方の GKE クラスタを先にバージョンアップし、サービスメッシュのトラフィック制御を使ってバージョンアップしたクラスタ側に少量のトラフィックを流して問題がないことを確認しながら段階的に比重をあげていく、といった「基盤部分も含めたカナリアリリース」のユースケースも容易に実現できるようになる見込みです。
もちろん公式ドキュメントにもマルチクラスタメッシュの構築に関する記載はあるのですが、単にクラスタ間で分散されたことを確認しただけで終わっており、ルーティングの設定やメッシュの外からの通信に関する記載はなかったため、今回はここら辺も含めて一気通貫でご紹介したいと思います。もしこれから Anthos Service Mesh 環境の利用を検討している方は参考にしてみてはいかがでしょうか。
構築するシステムについて 次の図に示すように限定公開クラスタおよび承認済みネットワーク機能を有効化した単一リージョンの複数 GKE クラスタに対して Anthos Service Mesh (マネージドコントロールプレーン)を導入し、サービスメッシュ上でサンプルアプリケーションを動かしていきたいと思います。なお、今回の例では GKE、Anthos Service Mesh のいずれのリリースチャンネルについても安定性重視の Stable チャンネルを採用しています。
それでは構築していきましょう 公式ドキュメントを参考にしつつ、公式ドキュメントに書かれていない部分を補足しながら構築をしていきたいと思います。
https://cloud.google.com/service-mesh/docs/unified-install/gke-install-multi-cluster
Step1. VPC ネットワークの作成 まずは GKE ノードを配置する VPC ネットワークおよび東京リージョンにサブネットを作成します。今回の例では GKE ノードからプライベートネットワーク経由で Artifact Registry などの他のマネージドサービスへアクセスできるように限定公開の Google アクセスをオンにしています。
VPCネットワークの作成 # 環境変数の設定 export NETWORK=&#34;matt-vpc&#34; export SUBNET=&#34;matt-private-vm&#34; export LOCATION=&#34;asia-northeast1&#34; export IP_RANGE=&#34;172.16.0.0/16&#34;  # VPC ネットワークの作成 gcloud compute networks create ${NETWORK} --subnet-mode=custom  # サブネットの作成 gcloud compute networks subnets create ${SUBNET} \  --network=${NETWORK} --range=${IP_RANGE} --region=${LOCATION} \  --enable-private-ip-google-access  プライベートネットワーク経由でインターネット上の Docker Hub などへ接続できるよう Cloud NAT も作成しておきます。"><meta name=author content><link rel=canonical href=https://chacco38.github.io/posts/2021/12/gcp-multi-asm-cluster/><link crossorigin=anonymous href=/assets/css/stylesheet.min.317d4c109e98a8137e18d0fd1222603a2a157f4e40f59a79576eb3861cc09531.css integrity="sha256-MX1MEJ6YqBN+GND9EiJgOioVf05A9Zp5V26zhhzAlTE=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.min.4dcb3c4f38462f66c6b6137227726f5543cb934cca9788f041c087e374491df2.js integrity="sha256-Tcs8TzhGL2bGthNyJ3JvVUPLk0zKl4jwQcCH43RJHfI=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://chacco38.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://chacco38.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://chacco38.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://chacco38.github.io/apple-touch-icon.png><link rel=mask-icon href=https://chacco38.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="単一リージョンの複数 GKE クラスタと Anthos Service Mesh でマルチクラスタメッシュ環境を構築してみた"><meta property="og:description" content="はじめに みなさん、こんにちは。今回は単一リージョンに展開した複数 GKE クラスタを単一の Anthos Service Mesh 環境に追加し、GKE クラスタ間で負荷分散を行う方法についてご紹介していきたいと思います。
複数 GKE クラスタでマルチクラスタメッシュを構築することにより、片方の GKE クラスタを先にバージョンアップし、サービスメッシュのトラフィック制御を使ってバージョンアップしたクラスタ側に少量のトラフィックを流して問題がないことを確認しながら段階的に比重をあげていく、といった「基盤部分も含めたカナリアリリース」のユースケースも容易に実現できるようになる見込みです。
もちろん公式ドキュメントにもマルチクラスタメッシュの構築に関する記載はあるのですが、単にクラスタ間で分散されたことを確認しただけで終わっており、ルーティングの設定やメッシュの外からの通信に関する記載はなかったため、今回はここら辺も含めて一気通貫でご紹介したいと思います。もしこれから Anthos Service Mesh 環境の利用を検討している方は参考にしてみてはいかがでしょうか。
構築するシステムについて 次の図に示すように限定公開クラスタおよび承認済みネットワーク機能を有効化した単一リージョンの複数 GKE クラスタに対して Anthos Service Mesh (マネージドコントロールプレーン)を導入し、サービスメッシュ上でサンプルアプリケーションを動かしていきたいと思います。なお、今回の例では GKE、Anthos Service Mesh のいずれのリリースチャンネルについても安定性重視の Stable チャンネルを採用しています。
それでは構築していきましょう 公式ドキュメントを参考にしつつ、公式ドキュメントに書かれていない部分を補足しながら構築をしていきたいと思います。
https://cloud.google.com/service-mesh/docs/unified-install/gke-install-multi-cluster
Step1. VPC ネットワークの作成 まずは GKE ノードを配置する VPC ネットワークおよび東京リージョンにサブネットを作成します。今回の例では GKE ノードからプライベートネットワーク経由で Artifact Registry などの他のマネージドサービスへアクセスできるように限定公開の Google アクセスをオンにしています。
VPCネットワークの作成 # 環境変数の設定 export NETWORK=&#34;matt-vpc&#34; export SUBNET=&#34;matt-private-vm&#34; export LOCATION=&#34;asia-northeast1&#34; export IP_RANGE=&#34;172.16.0.0/16&#34;  # VPC ネットワークの作成 gcloud compute networks create ${NETWORK} --subnet-mode=custom  # サブネットの作成 gcloud compute networks subnets create ${SUBNET} \  --network=${NETWORK} --range=${IP_RANGE} --region=${LOCATION} \  --enable-private-ip-google-access  プライベートネットワーク経由でインターネット上の Docker Hub などへ接続できるよう Cloud NAT も作成しておきます。"><meta property="og:type" content="article"><meta property="og:url" content="https://chacco38.github.io/posts/2021/12/gcp-multi-asm-cluster/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2021-12-09T00:00:00+00:00"><meta property="article:modified_time" content="2021-12-09T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="単一リージョンの複数 GKE クラスタと Anthos Service Mesh でマルチクラスタメッシュ環境を構築してみた"><meta name=twitter:description content="はじめに みなさん、こんにちは。今回は単一リージョンに展開した複数 GKE クラスタを単一の Anthos Service Mesh 環境に追加し、GKE クラスタ間で負荷分散を行う方法についてご紹介していきたいと思います。
複数 GKE クラスタでマルチクラスタメッシュを構築することにより、片方の GKE クラスタを先にバージョンアップし、サービスメッシュのトラフィック制御を使ってバージョンアップしたクラスタ側に少量のトラフィックを流して問題がないことを確認しながら段階的に比重をあげていく、といった「基盤部分も含めたカナリアリリース」のユースケースも容易に実現できるようになる見込みです。
もちろん公式ドキュメントにもマルチクラスタメッシュの構築に関する記載はあるのですが、単にクラスタ間で分散されたことを確認しただけで終わっており、ルーティングの設定やメッシュの外からの通信に関する記載はなかったため、今回はここら辺も含めて一気通貫でご紹介したいと思います。もしこれから Anthos Service Mesh 環境の利用を検討している方は参考にしてみてはいかがでしょうか。
構築するシステムについて 次の図に示すように限定公開クラスタおよび承認済みネットワーク機能を有効化した単一リージョンの複数 GKE クラスタに対して Anthos Service Mesh (マネージドコントロールプレーン)を導入し、サービスメッシュ上でサンプルアプリケーションを動かしていきたいと思います。なお、今回の例では GKE、Anthos Service Mesh のいずれのリリースチャンネルについても安定性重視の Stable チャンネルを採用しています。
それでは構築していきましょう 公式ドキュメントを参考にしつつ、公式ドキュメントに書かれていない部分を補足しながら構築をしていきたいと思います。
https://cloud.google.com/service-mesh/docs/unified-install/gke-install-multi-cluster
Step1. VPC ネットワークの作成 まずは GKE ノードを配置する VPC ネットワークおよび東京リージョンにサブネットを作成します。今回の例では GKE ノードからプライベートネットワーク経由で Artifact Registry などの他のマネージドサービスへアクセスできるように限定公開の Google アクセスをオンにしています。
VPCネットワークの作成 # 環境変数の設定 export NETWORK=&#34;matt-vpc&#34; export SUBNET=&#34;matt-private-vm&#34; export LOCATION=&#34;asia-northeast1&#34; export IP_RANGE=&#34;172.16.0.0/16&#34;  # VPC ネットワークの作成 gcloud compute networks create ${NETWORK} --subnet-mode=custom  # サブネットの作成 gcloud compute networks subnets create ${SUBNET} \  --network=${NETWORK} --range=${IP_RANGE} --region=${LOCATION} \  --enable-private-ip-google-access  プライベートネットワーク経由でインターネット上の Docker Hub などへ接続できるよう Cloud NAT も作成しておきます。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://chacco38.github.io/posts/"},{"@type":"ListItem","position":2,"name":"単一リージョンの複数 GKE クラスタと Anthos Service Mesh でマルチクラスタメッシュ環境を構築してみた","item":"https://chacco38.github.io/posts/2021/12/gcp-multi-asm-cluster/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"単一リージョンの複数 GKE クラスタと Anthos Service Mesh でマルチクラスタメッシュ環境を構築してみた","name":"単一リージョンの複数 GKE クラスタと Anthos Service Mesh でマルチクラスタメッシュ環境を構築してみた","description":"はじめに みなさん、こんにちは。今回は単一リージョンに展開した複数 GKE クラスタを単一の Anthos Service Mesh 環境に追加し、GKE クラスタ間で負荷分散を行う方法についてご紹介していきたいと思います。\n複数 GKE クラスタでマルチクラスタメッシュを構築することにより、片方の GKE クラスタを先にバージョンアップし、サービスメッシュのトラフィック制御を使ってバージョンアップしたクラスタ側に少量のトラフィックを流して問題がないことを確認しながら段階的に比重をあげていく、といった「基盤部分も含めたカナリアリリース」のユースケースも容易に実現できるようになる見込みです。\nもちろん公式ドキュメントにもマルチクラスタメッシュの構築に関する記載はあるのですが、単にクラスタ間で分散されたことを確認しただけで終わっており、ルーティングの設定やメッシュの外からの通信に関する記載はなかったため、今回はここら辺も含めて一気通貫でご紹介したいと思います。もしこれから Anthos Service Mesh 環境の利用を検討している方は参考にしてみてはいかがでしょうか。\n構築するシステムについて 次の図に示すように限定公開クラスタおよび承認済みネットワーク機能を有効化した単一リージョンの複数 GKE クラスタに対して Anthos Service Mesh (マネージドコントロールプレーン)を導入し、サービスメッシュ上でサンプルアプリケーションを動かしていきたいと思います。なお、今回の例では GKE、Anthos Service Mesh のいずれのリリースチャンネルについても安定性重視の Stable チャンネルを採用しています。\nそれでは構築していきましょう 公式ドキュメントを参考にしつつ、公式ドキュメントに書かれていない部分を補足しながら構築をしていきたいと思います。\nhttps://cloud.google.com/service-mesh/docs/unified-install/gke-install-multi-cluster\nStep1. VPC ネットワークの作成 まずは GKE ノードを配置する VPC ネットワークおよび東京リージョンにサブネットを作成します。今回の例では GKE ノードからプライベートネットワーク経由で Artifact Registry などの他のマネージドサービスへアクセスできるように限定公開の Google アクセスをオンにしています。\nVPCネットワークの作成 # 環境変数の設定 export NETWORK=\u0026#34;matt-vpc\u0026#34; export SUBNET=\u0026#34;matt-private-vm\u0026#34; export LOCATION=\u0026#34;asia-northeast1\u0026#34; export IP_RANGE=\u0026#34;172.16.0.0/16\u0026#34;  # VPC ネットワークの作成 gcloud compute networks create ${NETWORK} --subnet-mode=custom  # サブネットの作成 gcloud compute networks subnets create ${SUBNET} \\  --network=${NETWORK} --range=${IP_RANGE} --region=${LOCATION} \\  --enable-private-ip-google-access  プライベートネットワーク経由でインターネット上の Docker Hub などへ接続できるよう Cloud NAT も作成しておきます。","keywords":["Google Cloud","Google Kubernetes Engine(GKE)","Anthos Service Mesh","Kubernetes","Istio"],"articleBody":"はじめに みなさん、こんにちは。今回は単一リージョンに展開した複数 GKE クラスタを単一の Anthos Service Mesh 環境に追加し、GKE クラスタ間で負荷分散を行う方法についてご紹介していきたいと思います。\n複数 GKE クラスタでマルチクラスタメッシュを構築することにより、片方の GKE クラスタを先にバージョンアップし、サービスメッシュのトラフィック制御を使ってバージョンアップしたクラスタ側に少量のトラフィックを流して問題がないことを確認しながら段階的に比重をあげていく、といった「基盤部分も含めたカナリアリリース」のユースケースも容易に実現できるようになる見込みです。\nもちろん公式ドキュメントにもマルチクラスタメッシュの構築に関する記載はあるのですが、単にクラスタ間で分散されたことを確認しただけで終わっており、ルーティングの設定やメッシュの外からの通信に関する記載はなかったため、今回はここら辺も含めて一気通貫でご紹介したいと思います。もしこれから Anthos Service Mesh 環境の利用を検討している方は参考にしてみてはいかがでしょうか。\n構築するシステムについて 次の図に示すように限定公開クラスタおよび承認済みネットワーク機能を有効化した単一リージョンの複数 GKE クラスタに対して Anthos Service Mesh (マネージドコントロールプレーン)を導入し、サービスメッシュ上でサンプルアプリケーションを動かしていきたいと思います。なお、今回の例では GKE、Anthos Service Mesh のいずれのリリースチャンネルについても安定性重視の Stable チャンネルを採用しています。\nそれでは構築していきましょう 公式ドキュメントを参考にしつつ、公式ドキュメントに書かれていない部分を補足しながら構築をしていきたいと思います。\nhttps://cloud.google.com/service-mesh/docs/unified-install/gke-install-multi-cluster\nStep1. VPC ネットワークの作成 まずは GKE ノードを配置する VPC ネットワークおよび東京リージョンにサブネットを作成します。今回の例では GKE ノードからプライベートネットワーク経由で Artifact Registry などの他のマネージドサービスへアクセスできるように限定公開の Google アクセスをオンにしています。\nVPCネットワークの作成 # 環境変数の設定 export NETWORK=\"matt-vpc\" export SUBNET=\"matt-private-vm\" export LOCATION=\"asia-northeast1\" export IP_RANGE=\"172.16.0.0/16\"  # VPC ネットワークの作成 gcloud compute networks create ${NETWORK} --subnet-mode=custom  # サブネットの作成 gcloud compute networks subnets create ${SUBNET} \\  --network=${NETWORK} --range=${IP_RANGE} --region=${LOCATION} \\  --enable-private-ip-google-access  プライベートネットワーク経由でインターネット上の Docker Hub などへ接続できるよう Cloud NAT も作成しておきます。\nCloud NATの作成 # 環境変数の設定 export NAT_GATEWAY=\"matt-tokyo-nat\" export NAT_ROUTER=\"matt-tokyo-router\"  # Cloud Router の作成 (東京リージョン) gcloud compute routers create ${NAT_ROUTER} \\  --network=${NETWORK} --region=${LOCATION}  # Cloud NAT の作成 (東京リージョン) gcloud compute routers nats create ${NAT_GATEWAY} \\  --router=${NAT_ROUTER} \\  --router-region=${LOCATION} \\  --auto-allocate-nat-external-ips \\  --nat-all-subnet-ip-ranges \\  --enable-logging  Step2. GKE クラスタの作成 次に GKE クラスタを作成していきましょう。 Anthos Service Mesh の導入には次のような前提条件を満たす必要があるため、今回はこちらを満たした上で、セキュリティの観点から限定公開クラスタおよび承認済みネットワークの有効化、安定性の観点から Stable チャンネルを指定しています。\n 4 vCPU 以上を搭載したノード 合計 8 vCPU 以上を搭載したノードプール GKE Workload Identity の有効化 GKE リリースチャンネルへの登録 (※1)  ※1: Anthos Service Mesh のマネージドコントロールプレーン機能を使う場合のみ\nGKEクラスタの作成 # 環境変数の設定 export PROJECT_ID=`gcloud config list --format \"value(core.project)\"` export CLUSTER_1=\"matt-tokyo-cluster-1\" export CLUSTER_2=\"matt-tokyo-cluster-2\" export MASTER_IP_RANGE_1=\"192.168.0.0/28\" export MASTER_IP_RANGE_2=\"192.168.8.0/28\" export CTX_1=\"gke_${PROJECT_ID}_${LOCATION}_${CLUSTER_1}\" export CTX_2=\"gke_${PROJECT_ID}_${LOCATION}_${CLUSTER_2}\"  # GKE クラスタ #1 の作成 gcloud container clusters create ${CLUSTER_1} \\  --region=${LOCATION} \\  --machine-type=\"e2-standard-4\" \\  --num-nodes=\"1\" \\  --enable-autoscaling --min-nodes=\"1\" --max-nodes=\"3\" \\  --enable-private-nodes --master-ipv4-cidr=${MASTER_IP_RANGE_1} \\  --enable-master-global-access \\  --enable-ip-alias --network=${NETWORK} --subnetwork=${SUBNET} \\  --enable-master-authorized-networks \\  --workload-pool=\"${PROJECT_ID}.svc.id.goog\" \\  --release-channel=\"stable\"  # GKE クラスタ #2 の作成 gcloud container clusters create ${CLUSTER_2} \\  --region=${LOCATION} \\  --machine-type=\"e2-standard-4\" \\  --num-nodes=\"1\" \\  --enable-autoscaling --min-nodes=\"1\" --max-nodes=\"3\" \\  --enable-private-nodes --master-ipv4-cidr=${MASTER_IP_RANGE_2} \\  --enable-master-global-access \\  --enable-ip-alias --network=${NETWORK} --subnetwork=${SUBNET} \\  --enable-master-authorized-networks \\  --workload-pool=\"${PROJECT_ID}.svc.id.goog\" \\  --release-channel=\"stable\"  前提条件の詳細については次の公式ドキュメントをご参照ください。\nhttps://cloud.google.com/service-mesh/docs/unified-install/prerequisites\nStep3. Anthos Service Mesh のインストール 管理ツールのダウンロード 最初に Anthos Service Mesh v1.11 から正式な管理ツールとなった asmcli をダウンロードします。\nasmcliツールのダウンロード curl https://storage.googleapis.com/csm-artifacts/asm/asmcli_1.11  asmcli  # 実行権限の付与 chmod +x asmcli  GKE クラスタ #1 へのインストール まずは GKE クラスタ #1 に Anthos Service Mesh をインストールしていきましょう。Kubernetes API へ接続できるように GKE コントロールプレーンの承認済みネットワークに Cloud Shell の IP アドレスを登録し、kubectl を実行できるようにクラスタ認証情報を取得します。\nクラスタ認証情報の取得(クラスタ#1) # CloudShellの承認済みネットワーク登録 gcloud container clusters update ${CLUSTER_1} \\  --region ${LOCATION} \\  --enable-master-authorized-networks \\  --master-authorized-networks \\  \"$(dig +short myip.opendns.com @resolver1.opendns.com)/32\"  # クラスタ認証情報の取得 gcloud container clusters get-credentials ${CLUSTER_1} \\  --region ${LOCATION}  次に asmcli を使って Anthos Service Mesh をインストールします。コマンドが完了するまでおおよそ 5 分程度かかりました。\nAnthos Service Meshのインストール(クラスタ#1) ./asmcli install \\  --project_id ${PROJECT_ID} \\  --cluster_location ${LOCATION} \\  --cluster_name ${CLUSTER_1} \\  --managed \\  --channel \"stable\" \\  --enable-all \\  --output_dir ${CLUSTER_1}  次のようなメッセージが出力されましたらインストールに成功です。\nインストール成功時のメッセージ出力 asmcli: Successfully installed ASM.  GKE クラスタ #2 へのインストール 同様に GKE クラスタ #2 にも Anthos Service Mesh をインストールしましょう。\nAnthos Service Meshのインストール(クラスタ#2) # CloudShellの承認済みネットワーク登録 gcloud container clusters update ${CLUSTER_2} \\  --region ${LOCATION} \\  --enable-master-authorized-networks \\  --master-authorized-networks \\  \"$(dig +short myip.opendns.com @resolver1.opendns.com)/32\"  # クラスタ認証情報の取得 gcloud container clusters get-credentials ${CLUSTER_2} \\  --region ${LOCATION}  # Anthos Service Mesh のインストール ./asmcli install \\  --project_id ${PROJECT_ID} \\  --cluster_location ${LOCATION} \\  --cluster_name ${CLUSTER_2} \\  --managed \\  --channel \"stable\" \\  --enable-all \\  --output_dir ${CLUSTER_2}  ファイアウォールルールの更新 (限定公開クラスタ時のみ) 限定公開クラスタに Anthos Service Mesh をインストールした場合は、コントロールプレーンからのポート 15017 による通信を追加で許可する必要があります。次のコマンド実行してコントロールプレーンからのポート 15017 による通信を許可します。\nファイアウォールルールの更新(限定公開クラスタ時のみ) # 既存のファイアウォールルールに 15017/TCP の許可ルールを追加 (東京リージョン) gcloud compute firewall-rules update \\  $(gcloud compute firewall-rules list \\  --filter=\"name~${CLUSTER_1}-.*-master\" --format=\"value(name)\") \\  --allow tcp:10250,tcp:443,tcp:15017  # 既存のファイアウォールルールに 15017/TCP の許可ルールを追加 (大阪リージョン) gcloud compute firewall-rules update \\  $(gcloud compute firewall-rules list \\  --filter=\"name~${CLUSTER_2}-.*-master\" --format=\"value(name)\") \\  --allow tcp:10250,tcp:443,tcp:15017  Step4. マルチクラスタメッシュの設定 クラスタ間通信の許可 クラスタをまたがってのサービス間通信ができるように次のコマンドを実行してファイアウォールルール \"VPCネットワーク名\"-istio-multicluster-pods を新たに作成します。\nクラスタ間通信の許可 # 環境変数の設定 CLUSTER_1_CIDR=$(gcloud container clusters list \\  --filter=\"name~${CLUSTER_1}\" --format='value(clusterIpv4Cidr)') CLUSTER_2_CIDR=$(gcloud container clusters list \\  --filter=\"name~${CLUSTER_2}\" --format='value(clusterIpv4Cidr)') CLUSTER_1_NETTAG=$(gcloud compute instances list \\  --filter=\"name~${CLUSTER_1::20}\" --format='value(tags.items.[0])' | \\  grep ${CLUSTER_1} | sort -u) CLUSTER_2_NETTAG=$(gcloud compute instances list \\  --filter=\"name~${CLUSTER_2::20}\" --format='value(tags.items.[0])' | \\  grep ${CLUSTER_2} | sort -u)  # クラスタ間通信を許可するファイアウォールルールの作成 gcloud compute firewall-rules create \"${NETWORK}-istio-multicluster-pods\" \\  --network=${NETWORK} \\  --allow=tcp,udp,icmp,esp,ah,sctp \\  --direction=INGRESS \\  --priority=900 \\  --source-ranges=\"${CLUSTER_1_CIDR},${CLUSTER_2_CIDR}\" \\  --target-tags=\"${CLUSTER_1_NETTAG},${CLUSTER_2_NETTAG}\"  クラスタ間サービスディスカバリの設定 次のコマンドを実行し、クラスタ間でサービスの自動検出ができるように asmcli を使って設定を行います。\nクラスタ間サービスディスカバリの設定 ./asmcli create-mesh ${PROJECT_ID} \\  ${PROJECT_ID}/${LOCATION}/${CLUSTER_1} \\  ${PROJECT_ID}/${LOCATION}/${CLUSTER_2}  シークレット情報の更新 (限定公開クラスタ時のみ) 限定公開クラスタで構築した場合は、Anthos Service Mesh コントロールプレーンから他の GKE クラスタコントロールプレーンへプライベートネットワーク経由でアクセスできるようにシークレット情報を書き換えましょう。\nシークレット情報の更新(限定公開クラスタ時のみ) # 環境変数の設定 CLUSTER_1_PRIV_IP=$(gcloud container clusters describe \"${CLUSTER_1}\" \\  --region \"${LOCATION}\" --format \"value(privateClusterConfig.privateEndpoint)\") CLUSTER_2_PRIV_IP=$(gcloud container clusters describe \"${CLUSTER_2}\" \\  --region \"${LOCATION}\" --format \"value(privateClusterConfig.privateEndpoint)\")  # プライベートエンドポイントに書き換えたシークレット情報の作成 (クラスタ#1) ./${CLUSTER_1}/istioctl x create-remote-secret \\  --context=${CTX_1} --name=${CLUSTER_1} \\  --server=https://${CLUSTER_1_PRIV_IP}  ${CTX_1}.secret  # プライベートエンドポイントに書き換えたシークレット情報の作成 (クラスタ#2) ./${CLUSTER_1}/istioctl x create-remote-secret \\  --context=${CTX_2} --name=${CLUSTER_2} \\  --server=https://${CLUSTER_2_PRIV_IP}  ${CTX_2}.secret  # シークレット情報の更新 (クラスタ#1) kubectl apply -f ${CTX_2}.secret --context=${CTX_1}  # シークレット情報の更新 (クラスタ#2) kubectl apply -f ${CTX_1}.secret --context=${CTX_2}  ここまで終わりましたらクラスタ間で Kubernetes サービスがロードバランシングされるようになります。\nクラスタ間ロードバランシングの動作確認 構築はまだ続きますがいったんこの状態で、Anthos Service Mesh をインストールした際に –output_dir で指定したディレクトリへ格納されているサンプルアプリケーションの中から HelloWorld と Sleep というアプリケーションを使用して、クラスタ間で負荷が分散されることを実際に確認していきたいと思います。サンプルアプリケーションの詳細につきましては次の URL をご参照ください。\nhttps://github.com/istio/istio/tree/master/samples\n現時点では何もルーティング設定をしていないため、次の図のように 50% ずつトラフィックが振り分けられる状態を確認できるかと思います。\nサンプルアプリケーションのデプロイ それではサンプルアプリケーションをデプロイしていきましょう。まずは次のコマンドでサンプルアプリケーション用の Namespace を新たに作成します。\nサンプルアプリケーション用Namespaceの作成 # 環境変数の設定 export SAMPLE_NAMESPACE=\"sample\"  # 両クラスタにサンプルアプリケーション用 Namespace リソースの作成 for CTX in ${CTX_1} ${CTX_2} do  kubectl create --context=${CTX} namespace ${SAMPLE_NAMESPACE}  kubectl label --context=${CTX} namespace ${SAMPLE_NAMESPACE} \\  istio.io/rev=asm-managed-stable --overwrite done  次に HelloWorld および Sleep アプリケーションをデプロイしましょう。どちらのクラスタ上の Pod に振り分けられたかをわかりやすくするため、クラスタ #1 に HelloWorld アプリケーションの v1、クラスタ #2 に v2 をデプロイしています。\nサンプルアプリケーションのデプロイ # 両クラスタに HelloWorld サービスのデプロイ for CTX in ${CTX_1} ${CTX_2} do  kubectl apply --context=${CTX} -n ${SAMPLE_NAMESPACE} \\  -f ${CLUSTER_1}/istio-1.11.2-asm.17/samples/helloworld/helloworld.yaml \\  -l service=\"helloworld\" done  # クラスタ #1 に HelloWorld アプリケーションの v1 をデプロイ kubectl apply --context=${CTX_1} -n ${SAMPLE_NAMESPACE} \\  -f ${CLUSTER_1}/istio-1.11.2-asm.17/samples/helloworld/helloworld.yaml \\  -l version=\"v1\"  # クラスタ #2 に HelloWorld アプリケーションの v2 をデプロイ kubectl apply --context=${CTX_2} -n ${SAMPLE_NAMESPACE} \\  -f ${CLUSTER_1}/istio-1.11.2-asm.17/samples/helloworld/helloworld.yaml \\  -l version=\"v2\"  # 両クラスタに Sleep サービス、アプリケーションのデプロイ for CTX in ${CTX_1} ${CTX_2} do  kubectl apply --context=${CTX} -n ${SAMPLE_NAMESPACE} \\  -f ${CLUSTER_1}/istio-1.11.2-asm.17/samples/sleep/sleep.yaml done  サービス間通信の実行 それでは Sleep アプリケーションから HelloWorld アプリケーションへのサービス間通信をしてみましょう。次のコマンドでは各クラスタ上の Sleep アプリケーションからそれぞれ 10 回ずつ HelloWorld サービスへの通信を実施しています。\nサービス間通信の実行例 for CTX in ${CTX_1} ${CTX_2} do  for x in `seq 1 10`  do  kubectl exec --context=\"${CTX}\" -n sample -c sleep \\  \"$(kubectl get pod --context=\"${CTX}\" -n sample -l \\  app=sleep -o jsonpath='{.items[0].metadata.name}')\" \\  -- curl -sS helloworld.${SAMPLE_NAMESPACE}:5000/hello  done  echo '---' done  次の出力例のように両クラスタから v1 と v2 の Pod へランダムで 50% ずつトラフィックが振り分けられる状態を確認できるかと思います。\nメッセージ出力例 Hello version: v1, instance: helloworld-v1-776f57d5f6-62c9f Hello version: v1, instance: helloworld-v1-776f57d5f6-62c9f Hello version: v2, instance: helloworld-v2-54df5f84b-ffpmb : --- : Hello version: v1, instance: helloworld-v1-776f57d5f6-62c9f Hello version: v2, instance: helloworld-v2-54df5f84b-ffpmb Hello version: v1, instance: helloworld-v1-776f57d5f6-62c9f  以上でクラスタ間ロードバランシングの動作確認は完了です。\nStep5. 高度なクラスタ間ロードバランシングの設定 次にもう少し高度なクラスタ間ロードバランシングの設定をしていきましょう。ユースケースはいくつかありますが、今回は次の図のように GKE クラスタ #2 側の GKE クラスタのアップグレード後にアプリケーションの動作に影響がないかを少量のトラフィックを流して確認し、問題ないことを確認できたらその比重を段階的にあげていく、といったカナリアリリースのシナリオを想定した振り分け制御を行っていきたいと思います。\nIstio リソースのデプロイ それでは設定していきましょう。まずは Istio VirtualService リソース1および Istio DestinationRule リソース2の定義ファイルを作成しましょう。例のように VirtualService リソースにサブセットごとの振り分けの重みづけを、DestinationRule リソースにサブセットの定義をします。\nhelloworld-virtualservice.yaml apiVersion: networking.istio.io/v1alpha3 kind: VirtualService metadata:  name: helloworld spec:  hosts:  - helloworld  http:  - route:  - destination:  host: helloworld  subset: v1  weight: 80  - destination:  host: helloworld  subset: v2  weight: 20  helloworld-destinationrule.yaml apiVersion: networking.istio.io/v1alpha3 kind: DestinationRule metadata:  name: helloworld spec:  host: helloworld  subsets:  - name: v1  labels:  version: v1  - name: v2  labels:  version: v2  次のコマンドで両クラスタに Istio リソースをデプロイしましょう。これで設定は終わりです。\nIstioリソースのデプロイ # 両クラスタに VirtualService リソースをデプロイ for CTX in ${CTX_1} ${CTX_2} do  kubectl apply --context=${CTX} -n ${SAMPLE_NAMESPACE} \\  -f helloworld-virtualservice.yaml done  # 両クラスタに DestinationRule リソースをデプロイ for CTX in ${CTX_1} ${CTX_2} do  kubectl apply --context=${CTX} -n ${SAMPLE_NAMESPACE} \\  -f helloworld-destinationrule.yaml done  カナリアリリースの動作確認 構築はまだ続きますがいったんこの状態で、クラスタ間で負荷が設定どおりの比重で分散されることを実際に確認していきたいと思います。クラスタ間ロードバランシングの動作確認と同様に Sleep アプリケーションから HelloWorld アプリケーションへのサービス間通信をしてみましょう。\nサービス間通信の実行例 for x in `seq 1 10` do  kubectl exec --context=\"${CTX_1}\" -n sample -c sleep \\  \"$(kubectl get pod --context=\"${CTX_1}\" -n sample -l \\  app=sleep -o jsonpath='{.items[0].metadata.name}')\" \\  -- curl -sS helloworld.${SAMPLE_NAMESPACE}:5000/hello done  10 回の実行では試行回数が少ないため誤差はあるかと思いますが、出力例のように v1 への振り分けが約 80%、v2 への振り分けが約 20% となることが確認できるかと思います。\nメッセージ出力例 Hello version: v1, instance: helloworld-v1-58d756cf5d-bs22v Hello version: v1, instance: helloworld-v1-58d756cf5d-bs22v Hello version: v2, instance: helloworld-v2-54df5f84b-ffpmb Hello version: v1, instance: helloworld-v1-58d756cf5d-bs22v Hello version: v1, instance: helloworld-v1-58d756cf5d-bs22v Hello version: v1, instance: helloworld-v1-58d756cf5d-bs22v Hello version: v1, instance: helloworld-v1-58d756cf5d-bs22v Hello version: v2, instance: helloworld-v2-54df5f84b-ffpmb Hello version: v1, instance: helloworld-v1-58d756cf5d-bs22v Hello version: v1, instance: helloworld-v1-58d756cf5d-bs22v  以上で少し高度なクラスタ間ロードバランシング設定の動作確認もできました。\nStep6. Ingress ゲートウェイの設定 さてここからは話題がガラッと変わり、メッシュの外からの通信を受け入れるための Ingress ゲートウェイの設定をしていきたいと思います。今回は次の図のように各クラスタに配置された Ingress ゲートウェイアプリケーションを束ねるようにマルチクラスタ Ingress およびマルチクラスタ Service を配置する構成を作っていきます。\nマルチクラスタ Ingress 機能の有効化 最初に次のコマンドを実行し、マルチクラスタ Ingress 機能を有効化しましょう。なお、今回はマルチクラスタ Ingress の設定を行うメインの GKE クラスタ(=構成クラスタ)として、GKE クラスタ #1 を登録しています。\nマルチクラスタIngress機能の有効化 gcloud container hub ingress enable \\  --config-membership=${CLUSTER_1}  Ingress ゲートウェイ定義ファイルの作成 今回は Anthos Service Mesh をインストールした際に --output_dir で指定したディレクトリへ Ingress ゲートウェイのサンプル定義ファイルが配置されているのでこちらをベースに作成していきたいと思います。まずはサンプル定義ファイルを複製し、マルチクラスタ Ingress 構成向けに MultiClusterService3、BackendConfig4、MultiClusterIngress5 の 3 種類のリソース定義ファイルを追加していきましょう。\nIngressゲートウェイ定義ファイルの作成準備 # サンプル定義ファイルを複製 cp -r ${CLUSTER_1}/samples/gateways/istio-ingressgateway .  # マルチクラスタ Ingress 定義ファイルを格納するディレクトリを作成 mkdir -p istio-ingressgateway/multicluster  # Service リソース定義から MultiClusterService リソース定義ファイルに書き換え mv istio-ingressgateway/service.yaml istio-ingressgateway/multicluster/multiclusterservice.yaml  # 新たな定義ファイルを 2 種類作成 touch istio-ingressgateway/multicluster/backendconfig.yaml touch istio-ingressgateway/multicluster/multiclusteringress.yaml  それでは MultiClusterService3、BackendConfig4、MultiClusterIngress5 の 3 種類のリソース定義ファイルを編集していきましょう。MultiClusterService は Service リソースをマルチクラスタに対応させたリソースという位置づけのため、基本的に Service リソースの設定値とほぼ変わりません。今回は Ingress をフロントに配置するので LoadBalancer タイプの定義を削除し、デフォルトの Cluster IP に変更しています。\nistio-ingressgateway/multicluster/multiclusterservice.yaml（差分） - apiVersion: v1 + apiVersion: networking.gke.io/v1 - kind: Service + kind: MultiClusterService  metadata:  name: istio-ingressgateway + annotations: + cloud.google.com/backend-config: '{\"default\": \"ingress-backendconfig\"}'  labels:  app: istio-ingressgateway  istio: ingressgateway  spec: - ports: - # status-port exposes a /healthz/ready endpoint that can be used with GKE Ingress health checks - - name: status-port - port: 15021 - protocol: TCP - targetPort: 15021 - # Any ports exposed in Gateway resources should be exposed here. - - name: http2 - port: 80 - - name: https - port: 443 - selector: - istio: ingressgateway - app: istio-ingressgateway - type: LoadBalancer + template: + spec: + ports: + # status-port exposes a /healthz/ready endpoint that can be used with GKE Ingress health checks + - name: status-port + port: 15021 + protocol: TCP + targetPort: 15021 + # Any ports exposed in Gateway resources should be exposed here. + - name: http2 + port: 80 + - name: https + port: 443 + selector: + istio: ingressgateway + app: istio-ingressgateway   BackendConfig リソースではバックエンドサービスである Ingress ゲートウェイアプリケーションのヘルスチェックに関する定義を記載します。Ingress ゲートウェイはヘルスチェック用パスとして /healthz/ready:15021 を用意しているため、こちらを設定しましょう。\nistio-ingressgateway/multicluster/backendconfig.yaml（差分） + apiVersion: cloud.google.com/v1 + kind: BackendConfig + metadata: + name: ingress-backendconfig + spec: + healthCheck: + requestPath: /healthz/ready + port: 15021 + type: HTTP   MultiClusterIngress は Ingress リソースをマルチクラスタに対応させたリソースという位置づけであり、基本的に Ingress リソースを定義するときと設定値はほぼ同じです。\nistio-ingressgateway/multicluster/multiclusteringress.yaml（差分） + apiVersion: networking.gke.io/v1beta1 + kind: MultiClusterIngress + metadata: + name: istio-ingressgateway + labels: + app: istio-ingressgateway + istio: ingressgateway + spec: + template: + spec: + backend: + serviceName: istio-ingressgateway + servicePort: 80   Ingress ゲートウェイのデプロイ まずは Ingress ゲートウェイリソースをデプロイする Namespace を新たに作成します。今回の例では istio-gateway という名前の Namespace を作成しています。\nIngress Gateway用のNamespace作成 # 環境変数の設定 export GATEWAY_NAMESPACE=\"istio-gateway\"  # 両クラスタにサンプルアプリケーション用 Namespace リソースの作成 for CTX in ${CTX_1} ${CTX_2} do  kubectl create --context=${CTX} namespace ${GATEWAY_NAMESPACE}  kubectl label --context=${CTX} namespace ${GATEWAY_NAMESPACE} \\  istio.io/rev=asm-managed-stable --overwrite done  次のコマンドを実行して Ingress ゲートウェイアプリケーションを両クラスタにデプロイしましょう。\nIngress Gatewayアプリケーションのデプロイ for CTX in ${CTX_1} ${CTX_2} do  kubectl apply -n ${GATEWAY_NAMESPACE} --context=${CTX} \\  -f istio-ingressgateway done  最後にマルチクラスタ Ingress リソースを構成クラスタである GKE クラスタ #1 に対してデプロイをしましょう。\nIngress Gatewayアプリケーションのデプロイ kubectl apply -n ${GATEWAY_NAMESPACE} --context=${CTX_1} \\  -f istio-ingressgateway/multicluster  以上で Ingress ゲートウェイのデプロイは終わりです。\nIstio リソースのデプロイ Ingress ゲートウェイを通じてメッシュの外から HelloWorld アプリケーションへ通信ができるように Istio リソースの定義を行っていきたいと思います。まずは Istio Gateway リソース6および Istio VirtualService リソース1の定義ファイルを作成しましょう。例のように Gateway リソースにメッシュ外から受け付けるポートとプロトコルを定義し、VirtualService リソースには Gateway に入ってきた通信のパターンマッチ条件と振り分け先バックエンドの指定をします。\nhelloworld-gateway.yaml apiVersion: networking.istio.io/v1alpha3 kind: Gateway metadata:  name: helloworld-gateway spec:  selector:  istio: ingressgateway  servers:  - port:  number: 80  name: http  protocol: HTTP  hosts:  - \"*\" --- apiVersion: networking.istio.io/v1alpha3 kind: VirtualService metadata:  name: helloworld-gateway spec:  hosts:  - \"*\"  gateways:  - helloworld-gateway  http:  - match:  - uri:  exact: /hello  route:  - destination:  host: helloworld  port:  number: 5000  次のコマンドで両クラスタに Istio リソースをデプロイし、アプリケーションへのインバウンド通信ができるように設定しましょう。\nIstioリソースのデプロイ for CTX in ${CTX_1} ${CTX_2} do  kubectl apply -n ${SAMPLE_NAMESPACE} --context=${CTX} \\  -f helloworld-gateway.yaml done  以上でメッシュ外からのアプリケーションへのインバウンド通信もできるようになりました。\nインバウンド通信の動作確認 それではメッシュ外からのアプリケーションへのインバウンド通信ができることを確認していきましょう。実行例のように Ingress ゲートウェイの外部 IP アドレスに対して curl コマンドを実行し、アクセスをしてみましょう。\nインバウンド通信の実行 # Ingress ゲートウェイの外部 IP アドレスの取得 INGRESS_GATEWAY_IP=$(kubectl --context=${CTX_1} \\  -n ${GATEWAY_NAMESPACE} get MultiClusterIngress \\  -o custom-columns=VIP:status.VIP --no-headers)  for x in `seq 1 10` do  curl http://${INGRESS_GATEWAY_IP}/hello done  次の出力例のように両クラスタから v1 と v2 の Pod へランダムで 50% ずつトラフィックが振り分けられる状態を確認できるかと思います。\nメッセージ出力例 Hello version: v1, instance: helloworld-v1-58d756cf5d-bs22v Hello version: v2, instance: helloworld-v2-54df5f84b-ffpmb Hello version: v1, instance: helloworld-v1-58d756cf5d-bs22v Hello version: v2, instance: helloworld-v2-54df5f84b-ffpmb Hello version: v2, instance: helloworld-v2-54df5f84b-ffpmb Hello version: v1, instance: helloworld-v1-58d756cf5d-bs22v Hello version: v1, instance: helloworld-v1-58d756cf5d-bs22v Hello version: v1, instance: helloworld-v1-58d756cf5d-bs22v Hello version: v2, instance: helloworld-v2-54df5f84b-ffpmb Hello version: v2, instance: helloworld-v2-54df5f84b-ffpmb  Step7. インバウンド通信に対する高度なロードバランシングの設定 メッシュの外からアプリケーションへのインバウンド通信に対する高度なロードバランシングの設定をしていきましょう。今回は Step5 のときとは逆に 80% を v2、20% を v1 に割り振るように設定していきたいと思います。\nIstio リソースの更新 それでは先ほど作成した Istio リソース定義ファイル helloworld-gateway.yaml の VirtualService リソース部分を編集し、サブセットごとの振り分け比重の定義を追加します。なお、サブセットの定義(DestinationRule リソース)については「Step5. 高度なクラスタ間ロードバランシングの設定」にて設定済みとなりますのでここでは省略します。\nhelloworld-gateway.yaml（差分）  apiVersion: networking.istio.io/v1alpha3  kind: VirtualService  metadata:  name: helloworld-gateway  spec:  hosts:  - \"*\"  gateways:  - helloworld-gateway  http:  - match:  - uri:  exact: /hello  route:  - destination:  host: helloworld  port:  number: 5000 + subset: v1 + weight: 20 + - destination: + host: helloworld + port: + number: 5000 + subset: v2 + weight: 80   それでは次のコマンドで Istio リソースを更新しましょう。これで設定は終わりです。\nIstioリソースの更新 for CTX in ${CTX_1} ${CTX_2} do  kubectl apply -n ${SAMPLE_NAMESPACE} --context=${CTX} \\  -f helloworld-gateway.yaml done  カナリアリリースの動作確認 それでは HelloWorld アプリケーションへの振り分けが設定どおりの比重で分散されることを実際に確認していきたいと思います。実行例のように Ingress ゲートウェイの外部 IP アドレスに対して curl コマンドを実行し、アクセスをしてみましょう。\nインバウンド通信の実行 # Ingress ゲートウェイの外部 IP アドレスの取得 INGRESS_GATEWAY_IP=$(kubectl --context=${CTX_1} \\  -n ${GATEWAY_NAMESPACE} get MultiClusterIngress \\  -o custom-columns=VIP:status.VIP --no-headers)  for x in `seq 1 10` do  curl http://${INGRESS_GATEWAY_IP}/hello done  10 回の実行では試行回数が少ないため誤差はあるかと思いますが、出力例のように v1 への振り分けが約 20%、v2 への振り分けが約 80% となることが確認できるかと思います。\nメッセージ出力例 Hello version: v2, instance: helloworld-v2-54df5f84b-ffpmb Hello version: v2, instance: helloworld-v2-54df5f84b-ffpmb Hello version: v2, instance: helloworld-v2-54df5f84b-ffpmb Hello version: v2, instance: helloworld-v2-54df5f84b-ffpmb Hello version: v2, instance: helloworld-v2-54df5f84b-ffpmb Hello version: v2, instance: helloworld-v2-54df5f84b-ffpmb Hello version: v1, instance: helloworld-v1-58d756cf5d-bs22v Hello version: v1, instance: helloworld-v1-58d756cf5d-bs22v Hello version: v2, instance: helloworld-v2-54df5f84b-ffpmb Hello version: v2, instance: helloworld-v2-54df5f84b-ffpmb  以上でメッシュの外からアプリケーションへのインバウンド通信に対する高度なロードバランシングの動作確認も終了です。お疲れ様でした。\n終わりに 今回は単一リージョンに展開した複数 GKE クラスタを単一の Anthos Service Mesh 環境に追加し、GKE クラスタ間で負荷分散を行う方法についてご紹介でしたがいかがだったでしょうか。\n複数 GKE クラスタでマルチクラスタメッシュを構築することにより、片方の GKE クラスタを先にバージョンアップし、サービスメッシュのトラフィック制御を使ってバージョンアップしたクラスタ側に少量のトラフィックを流して問題がないことを確認しながら段階的に比重をあげていく、といった「基盤部分も含めたカナリアリリース」のユースケースも容易に実現できるようになる見込みです。もしこれから Anthos Service Mesh 環境の利用を検討している方はマルチクラスタメッシュ構成についても検討してみてはいかがでしょうか。\n  Google Cloud は、Google LLC の商標または登録商標です。 その他、記載されている会社名および商品・製品・サービス名は、各社の商標または登録商標です。    VirtualService はトラフィックの振り分け、ルーティングを定義する Istio リソース ↩︎\n DestinationRule は転送先サービスのサブセット化や各種トラフィックポリシーを定義する Istio リソース ↩︎\n MultiClusterService は Service リソースを複数のクラスタ上に展開する GKE 独自のカスタムリソース ↩︎\n BackendConfig はバックエンドサービスのヘルスチェックを定義する GKE 独自のカスタムリソース ↩︎\n MultiClusterIngress はマルチクラスタに対応した Ingress リソースを定義する GKE 独自のカスタムリソース ↩︎\n Gateway は Ingress/Egress ゲートウェイで受け付けるポート、プロトコルを定義する Istio リソース ↩︎\n   ","wordCount":"1964","inLanguage":"en","datePublished":"2021-12-09T00:00:00Z","dateModified":"2021-12-09T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://chacco38.github.io/posts/2021/12/gcp-multi-asm-cluster/"},"publisher":{"@type":"Organization","name":"クラウドCoEの何でも屋","logo":{"@type":"ImageObject","url":"https://chacco38.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://chacco38.github.io/ accesskey=h title="クラウドCoEの何でも屋 (Alt + H)">クラウドCoEの何でも屋</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://chacco38.github.io/blog/ title=Blog><span>Blog</span></a></li><li><a href=https://chacco38.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://chacco38.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://chacco38.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://chacco38.github.io/posts/>Posts</a></div><h1 class=post-title>単一リージョンの複数 GKE クラスタと Anthos Service Mesh でマルチクラスタメッシュ環境を構築してみた</h1><div class=post-meta><span title="2021-12-09 00:00:00 +0000 UTC">December 9, 2021</span>&nbsp;·&nbsp;10 min&nbsp;|&nbsp;<a href=https://github.com/chacco38/chacco38.github.io/tree/main/content/posts/2021/12/gcp-multi-asm-cluster/index.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e3%81%af%e3%81%98%e3%82%81%e3%81%ab aria-label=はじめに>はじめに</a></li><li><a href=#%e6%a7%8b%e7%af%89%e3%81%99%e3%82%8b%e3%82%b7%e3%82%b9%e3%83%86%e3%83%a0%e3%81%ab%e3%81%a4%e3%81%84%e3%81%a6 aria-label=構築するシステムについて>構築するシステムについて</a></li><li><a href=#%e3%81%9d%e3%82%8c%e3%81%a7%e3%81%af%e6%a7%8b%e7%af%89%e3%81%97%e3%81%a6%e3%81%84%e3%81%8d%e3%81%be%e3%81%97%e3%82%87%e3%81%86 aria-label=それでは構築していきましょう>それでは構築していきましょう</a><ul><li><a href=#step1-vpc-%e3%83%8d%e3%83%83%e3%83%88%e3%83%af%e3%83%bc%e3%82%af%e3%81%ae%e4%bd%9c%e6%88%90 aria-label="Step1. VPC ネットワークの作成">Step1. VPC ネットワークの作成</a></li><li><a href=#step2-gke-%e3%82%af%e3%83%a9%e3%82%b9%e3%82%bf%e3%81%ae%e4%bd%9c%e6%88%90 aria-label="Step2. GKE クラスタの作成">Step2. GKE クラスタの作成</a></li><li><a href=#step3-anthos-service-mesh-%e3%81%ae%e3%82%a4%e3%83%b3%e3%82%b9%e3%83%88%e3%83%bc%e3%83%ab aria-label="Step3. Anthos Service Mesh のインストール">Step3. Anthos Service Mesh のインストール</a><ul><li><a href=#%e7%ae%a1%e7%90%86%e3%83%84%e3%83%bc%e3%83%ab%e3%81%ae%e3%83%80%e3%82%a6%e3%83%b3%e3%83%ad%e3%83%bc%e3%83%89 aria-label=管理ツールのダウンロード>管理ツールのダウンロード</a></li><li><a href=#gke-%e3%82%af%e3%83%a9%e3%82%b9%e3%82%bf-1-%e3%81%b8%e3%81%ae%e3%82%a4%e3%83%b3%e3%82%b9%e3%83%88%e3%83%bc%e3%83%ab aria-label="GKE クラスタ #1 へのインストール">GKE クラスタ #1 へのインストール</a></li><li><a href=#gke-%e3%82%af%e3%83%a9%e3%82%b9%e3%82%bf-2-%e3%81%b8%e3%81%ae%e3%82%a4%e3%83%b3%e3%82%b9%e3%83%88%e3%83%bc%e3%83%ab aria-label="GKE クラスタ #2 へのインストール">GKE クラスタ #2 へのインストール</a></li><li><a href=#%e3%83%95%e3%82%a1%e3%82%a4%e3%82%a2%e3%82%a6%e3%82%a9%e3%83%bc%e3%83%ab%e3%83%ab%e3%83%bc%e3%83%ab%e3%81%ae%e6%9b%b4%e6%96%b0-%e9%99%90%e5%ae%9a%e5%85%ac%e9%96%8b%e3%82%af%e3%83%a9%e3%82%b9%e3%82%bf%e6%99%82%e3%81%ae%e3%81%bf aria-label="ファイアウォールルールの更新 (限定公開クラスタ時のみ)">ファイアウォールルールの更新 (限定公開クラスタ時のみ)</a></li></ul></li><li><a href=#step4-%e3%83%9e%e3%83%ab%e3%83%81%e3%82%af%e3%83%a9%e3%82%b9%e3%82%bf%e3%83%a1%e3%83%83%e3%82%b7%e3%83%a5%e3%81%ae%e8%a8%ad%e5%ae%9a aria-label="Step4. マルチクラスタメッシュの設定">Step4. マルチクラスタメッシュの設定</a><ul><li><a href=#%e3%82%af%e3%83%a9%e3%82%b9%e3%82%bf%e9%96%93%e9%80%9a%e4%bf%a1%e3%81%ae%e8%a8%b1%e5%8f%af aria-label=クラスタ間通信の許可>クラスタ間通信の許可</a></li><li><a href=#%e3%82%af%e3%83%a9%e3%82%b9%e3%82%bf%e9%96%93%e3%82%b5%e3%83%bc%e3%83%93%e3%82%b9%e3%83%87%e3%82%a3%e3%82%b9%e3%82%ab%e3%83%90%e3%83%aa%e3%81%ae%e8%a8%ad%e5%ae%9a aria-label=クラスタ間サービスディスカバリの設定>クラスタ間サービスディスカバリの設定</a></li><li><a href=#%e3%82%b7%e3%83%bc%e3%82%af%e3%83%ac%e3%83%83%e3%83%88%e6%83%85%e5%a0%b1%e3%81%ae%e6%9b%b4%e6%96%b0-%e9%99%90%e5%ae%9a%e5%85%ac%e9%96%8b%e3%82%af%e3%83%a9%e3%82%b9%e3%82%bf%e6%99%82%e3%81%ae%e3%81%bf aria-label="シークレット情報の更新 (限定公開クラスタ時のみ)">シークレット情報の更新 (限定公開クラスタ時のみ)</a></li><li><a href=#%e3%82%af%e3%83%a9%e3%82%b9%e3%82%bf%e9%96%93%e3%83%ad%e3%83%bc%e3%83%89%e3%83%90%e3%83%a9%e3%83%b3%e3%82%b7%e3%83%b3%e3%82%b0%e3%81%ae%e5%8b%95%e4%bd%9c%e7%a2%ba%e8%aa%8d aria-label=クラスタ間ロードバランシングの動作確認>クラスタ間ロードバランシングの動作確認</a><ul><li><a href=#%e3%82%b5%e3%83%b3%e3%83%97%e3%83%ab%e3%82%a2%e3%83%97%e3%83%aa%e3%82%b1%e3%83%bc%e3%82%b7%e3%83%a7%e3%83%b3%e3%81%ae%e3%83%87%e3%83%97%e3%83%ad%e3%82%a4 aria-label=サンプルアプリケーションのデプロイ>サンプルアプリケーションのデプロイ</a></li><li><a href=#%e3%82%b5%e3%83%bc%e3%83%93%e3%82%b9%e9%96%93%e9%80%9a%e4%bf%a1%e3%81%ae%e5%ae%9f%e8%a1%8c aria-label=サービス間通信の実行>サービス間通信の実行</a></li></ul></li></ul></li><li><a href=#step5-%e9%ab%98%e5%ba%a6%e3%81%aa%e3%82%af%e3%83%a9%e3%82%b9%e3%82%bf%e9%96%93%e3%83%ad%e3%83%bc%e3%83%89%e3%83%90%e3%83%a9%e3%83%b3%e3%82%b7%e3%83%b3%e3%82%b0%e3%81%ae%e8%a8%ad%e5%ae%9a aria-label="Step5. 高度なクラスタ間ロードバランシングの設定">Step5. 高度なクラスタ間ロードバランシングの設定</a><ul><li><a href=#istio-%e3%83%aa%e3%82%bd%e3%83%bc%e3%82%b9%e3%81%ae%e3%83%87%e3%83%97%e3%83%ad%e3%82%a4 aria-label="Istio リソースのデプロイ">Istio リソースのデプロイ</a></li><li><a href=#%e3%82%ab%e3%83%8a%e3%83%aa%e3%82%a2%e3%83%aa%e3%83%aa%e3%83%bc%e3%82%b9%e3%81%ae%e5%8b%95%e4%bd%9c%e7%a2%ba%e8%aa%8d aria-label=カナリアリリースの動作確認>カナリアリリースの動作確認</a></li></ul></li><li><a href=#step6-ingress-%e3%82%b2%e3%83%bc%e3%83%88%e3%82%a6%e3%82%a7%e3%82%a4%e3%81%ae%e8%a8%ad%e5%ae%9a aria-label="Step6. Ingress ゲートウェイの設定">Step6. Ingress ゲートウェイの設定</a><ul><li><a href=#%e3%83%9e%e3%83%ab%e3%83%81%e3%82%af%e3%83%a9%e3%82%b9%e3%82%bf-ingress-%e6%a9%9f%e8%83%bd%e3%81%ae%e6%9c%89%e5%8a%b9%e5%8c%96 aria-label="マルチクラスタ Ingress 機能の有効化">マルチクラスタ Ingress 機能の有効化</a></li><li><a href=#ingress-%e3%82%b2%e3%83%bc%e3%83%88%e3%82%a6%e3%82%a7%e3%82%a4%e5%ae%9a%e7%be%a9%e3%83%95%e3%82%a1%e3%82%a4%e3%83%ab%e3%81%ae%e4%bd%9c%e6%88%90 aria-label="Ingress ゲートウェイ定義ファイルの作成">Ingress ゲートウェイ定義ファイルの作成</a></li><li><a href=#ingress-%e3%82%b2%e3%83%bc%e3%83%88%e3%82%a6%e3%82%a7%e3%82%a4%e3%81%ae%e3%83%87%e3%83%97%e3%83%ad%e3%82%a4 aria-label="Ingress ゲートウェイのデプロイ">Ingress ゲートウェイのデプロイ</a></li><li><a href=#istio-%e3%83%aa%e3%82%bd%e3%83%bc%e3%82%b9%e3%81%ae%e3%83%87%e3%83%97%e3%83%ad%e3%82%a4-1 aria-label="Istio リソースのデプロイ">Istio リソースのデプロイ</a></li><li><a href=#%e3%82%a4%e3%83%b3%e3%83%90%e3%82%a6%e3%83%b3%e3%83%89%e9%80%9a%e4%bf%a1%e3%81%ae%e5%8b%95%e4%bd%9c%e7%a2%ba%e8%aa%8d aria-label=インバウンド通信の動作確認>インバウンド通信の動作確認</a></li></ul></li><li><a href=#step7-%e3%82%a4%e3%83%b3%e3%83%90%e3%82%a6%e3%83%b3%e3%83%89%e9%80%9a%e4%bf%a1%e3%81%ab%e5%af%be%e3%81%99%e3%82%8b%e9%ab%98%e5%ba%a6%e3%81%aa%e3%83%ad%e3%83%bc%e3%83%89%e3%83%90%e3%83%a9%e3%83%b3%e3%82%b7%e3%83%b3%e3%82%b0%e3%81%ae%e8%a8%ad%e5%ae%9a aria-label="Step7. インバウンド通信に対する高度なロードバランシングの設定">Step7. インバウンド通信に対する高度なロードバランシングの設定</a><ul><li><a href=#istio-%e3%83%aa%e3%82%bd%e3%83%bc%e3%82%b9%e3%81%ae%e6%9b%b4%e6%96%b0 aria-label="Istio リソースの更新">Istio リソースの更新</a></li><li><a href=#%e3%82%ab%e3%83%8a%e3%83%aa%e3%82%a2%e3%83%aa%e3%83%aa%e3%83%bc%e3%82%b9%e3%81%ae%e5%8b%95%e4%bd%9c%e7%a2%ba%e8%aa%8d-1 aria-label=カナリアリリースの動作確認>カナリアリリースの動作確認</a></li></ul></li></ul></li><li><a href=#%e7%b5%82%e3%82%8f%e3%82%8a%e3%81%ab aria-label=終わりに>終わりに</a></li></ul></div></details></div><div class=post-content><h1 id=はじめに>はじめに<a hidden class=anchor aria-hidden=true href=#はじめに>#</a></h1><p>みなさん、こんにちは。今回は単一リージョンに展開した複数 GKE クラスタを単一の Anthos Service Mesh 環境に追加し、GKE クラスタ間で負荷分散を行う方法についてご紹介していきたいと思います。</p><p>複数 GKE クラスタでマルチクラスタメッシュを構築することにより、片方の GKE クラスタを先にバージョンアップし、サービスメッシュのトラフィック制御を使ってバージョンアップしたクラスタ側に少量のトラフィックを流して問題がないことを確認しながら段階的に比重をあげていく、といった「基盤部分も含めたカナリアリリース」のユースケースも容易に実現できるようになる見込みです。</p><p>もちろん公式ドキュメントにもマルチクラスタメッシュの構築に関する記載はあるのですが、単にクラスタ間で分散されたことを確認しただけで終わっており、ルーティングの設定やメッシュの外からの通信に関する記載はなかったため、今回はここら辺も含めて一気通貫でご紹介したいと思います。もしこれから Anthos Service Mesh 環境の利用を検討している方は参考にしてみてはいかがでしょうか。</p><h1 id=構築するシステムについて>構築するシステムについて<a hidden class=anchor aria-hidden=true href=#構築するシステムについて>#</a></h1><p>次の図に示すように限定公開クラスタおよび承認済みネットワーク機能を有効化した単一リージョンの複数 GKE クラスタに対して Anthos Service Mesh (マネージドコントロールプレーン)を導入し、サービスメッシュ上でサンプルアプリケーションを動かしていきたいと思います。なお、今回の例では GKE、Anthos Service Mesh のいずれのリリースチャンネルについても安定性重視の Stable チャンネルを採用しています。</p><p><img loading=lazy src=images/01-architecture.png alt=01-architecture.png></p><h1 id=それでは構築していきましょう>それでは構築していきましょう<a hidden class=anchor aria-hidden=true href=#それでは構築していきましょう>#</a></h1><p>公式ドキュメントを参考にしつつ、公式ドキュメントに書かれていない部分を補足しながら構築をしていきたいと思います。</p><p><a href=https://cloud.google.com/service-mesh/docs/unified-install/gke-install-multi-cluster>https://cloud.google.com/service-mesh/docs/unified-install/gke-install-multi-cluster</a></p><h2 id=step1-vpc-ネットワークの作成>Step1. VPC ネットワークの作成<a hidden class=anchor aria-hidden=true href=#step1-vpc-ネットワークの作成>#</a></h2><p>まずは GKE ノードを配置する VPC ネットワークおよび東京リージョンにサブネットを作成します。今回の例では GKE ノードからプライベートネットワーク経由で Artifact Registry などの他のマネージドサービスへアクセスできるように限定公開の Google アクセスをオンにしています。</p><figure class=xCodeBlock><figcaption class=xCodeBlock_title>VPCネットワークの作成</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 環境変数の設定</span>
</span></span><span style=display:flex><span>export NETWORK<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;matt-vpc&#34;</span>
</span></span><span style=display:flex><span>export SUBNET<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;matt-private-vm&#34;</span>
</span></span><span style=display:flex><span>export LOCATION<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;asia-northeast1&#34;</span>
</span></span><span style=display:flex><span>export IP_RANGE<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;172.16.0.0/16&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># VPC ネットワークの作成</span>
</span></span><span style=display:flex><span>gcloud compute networks create <span style=color:#e6db74>${</span>NETWORK<span style=color:#e6db74>}</span> --subnet-mode<span style=color:#f92672>=</span>custom
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># サブネットの作成</span>
</span></span><span style=display:flex><span>gcloud compute networks subnets create <span style=color:#e6db74>${</span>SUBNET<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --network<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>NETWORK<span style=color:#e6db74>}</span> --range<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>IP_RANGE<span style=color:#e6db74>}</span> --region<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>LOCATION<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>     --enable-private-ip-google-access</span></span></code></pre></div></div></figure><p>プライベートネットワーク経由でインターネット上の Docker Hub などへ接続できるよう Cloud NAT も作成しておきます。</p><figure class=xCodeBlock><figcaption class=xCodeBlock_title>Cloud NATの作成</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 環境変数の設定</span>
</span></span><span style=display:flex><span>export NAT_GATEWAY<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;matt-tokyo-nat&#34;</span>
</span></span><span style=display:flex><span>export NAT_ROUTER<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;matt-tokyo-router&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Cloud Router の作成 (東京リージョン)</span>
</span></span><span style=display:flex><span>gcloud compute routers create <span style=color:#e6db74>${</span>NAT_ROUTER<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --network<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>NETWORK<span style=color:#e6db74>}</span> --region<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>LOCATION<span style=color:#e6db74>}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Cloud NAT の作成 (東京リージョン)</span>
</span></span><span style=display:flex><span>gcloud compute routers nats create <span style=color:#e6db74>${</span>NAT_GATEWAY<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --router<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>NAT_ROUTER<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --router-region<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>LOCATION<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --auto-allocate-nat-external-ips <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --nat-all-subnet-ip-ranges <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --enable-logging</span></span></code></pre></div></div></figure><h2 id=step2-gke-クラスタの作成>Step2. GKE クラスタの作成<a hidden class=anchor aria-hidden=true href=#step2-gke-クラスタの作成>#</a></h2><p>次に GKE クラスタを作成していきましょう。 Anthos Service Mesh の導入には次のような前提条件を満たす必要があるため、今回はこちらを満たした上で、セキュリティの観点から限定公開クラスタおよび承認済みネットワークの有効化、安定性の観点から Stable チャンネルを指定しています。</p><ul><li>4 vCPU 以上を搭載したノード</li><li>合計 8 vCPU 以上を搭載したノードプール</li><li>GKE Workload Identity の有効化</li><li>GKE リリースチャンネルへの登録 (※1)</li></ul><p>※1: Anthos Service Mesh のマネージドコントロールプレーン機能を使う場合のみ</p><figure class=xCodeBlock><figcaption class=xCodeBlock_title>GKEクラスタの作成</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 環境変数の設定</span>
</span></span><span style=display:flex><span>export PROJECT_ID<span style=color:#f92672>=</span><span style=color:#e6db74>`</span>gcloud config list --format <span style=color:#e6db74>&#34;value(core.project)&#34;</span><span style=color:#e6db74>`</span>
</span></span><span style=display:flex><span>export CLUSTER_1<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;matt-tokyo-cluster-1&#34;</span>
</span></span><span style=display:flex><span>export CLUSTER_2<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;matt-tokyo-cluster-2&#34;</span>
</span></span><span style=display:flex><span>export MASTER_IP_RANGE_1<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;192.168.0.0/28&#34;</span>
</span></span><span style=display:flex><span>export MASTER_IP_RANGE_2<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;192.168.8.0/28&#34;</span>
</span></span><span style=display:flex><span>export CTX_1<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;gke_</span><span style=color:#e6db74>${</span>PROJECT_ID<span style=color:#e6db74>}</span><span style=color:#e6db74>_</span><span style=color:#e6db74>${</span>LOCATION<span style=color:#e6db74>}</span><span style=color:#e6db74>_</span><span style=color:#e6db74>${</span>CLUSTER_1<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>export CTX_2<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;gke_</span><span style=color:#e6db74>${</span>PROJECT_ID<span style=color:#e6db74>}</span><span style=color:#e6db74>_</span><span style=color:#e6db74>${</span>LOCATION<span style=color:#e6db74>}</span><span style=color:#e6db74>_</span><span style=color:#e6db74>${</span>CLUSTER_2<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># GKE クラスタ #1 の作成</span>
</span></span><span style=display:flex><span>gcloud container clusters create <span style=color:#e6db74>${</span>CLUSTER_1<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --region<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>LOCATION<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --machine-type<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;e2-standard-4&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --num-nodes<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;1&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --enable-autoscaling --min-nodes<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;1&#34;</span> --max-nodes<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;3&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --enable-private-nodes --master-ipv4-cidr<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>MASTER_IP_RANGE_1<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --enable-master-global-access <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --enable-ip-alias --network<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>NETWORK<span style=color:#e6db74>}</span> --subnetwork<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>SUBNET<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --enable-master-authorized-networks <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --workload-pool<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>PROJECT_ID<span style=color:#e6db74>}</span><span style=color:#e6db74>.svc.id.goog&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --release-channel<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;stable&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># GKE クラスタ #2 の作成</span>
</span></span><span style=display:flex><span>gcloud container clusters create <span style=color:#e6db74>${</span>CLUSTER_2<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --region<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>LOCATION<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --machine-type<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;e2-standard-4&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --num-nodes<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;1&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --enable-autoscaling --min-nodes<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;1&#34;</span> --max-nodes<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;3&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --enable-private-nodes --master-ipv4-cidr<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>MASTER_IP_RANGE_2<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --enable-master-global-access <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --enable-ip-alias --network<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>NETWORK<span style=color:#e6db74>}</span> --subnetwork<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>SUBNET<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --enable-master-authorized-networks <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --workload-pool<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>PROJECT_ID<span style=color:#e6db74>}</span><span style=color:#e6db74>.svc.id.goog&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --release-channel<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;stable&#34;</span></span></span></code></pre></div></div></figure><p>前提条件の詳細については次の公式ドキュメントをご参照ください。</p><p><a href=https://cloud.google.com/service-mesh/docs/unified-install/prerequisites>https://cloud.google.com/service-mesh/docs/unified-install/prerequisites</a></p><h2 id=step3-anthos-service-mesh-のインストール>Step3. Anthos Service Mesh のインストール<a hidden class=anchor aria-hidden=true href=#step3-anthos-service-mesh-のインストール>#</a></h2><h3 id=管理ツールのダウンロード>管理ツールのダウンロード<a hidden class=anchor aria-hidden=true href=#管理ツールのダウンロード>#</a></h3><p>最初に Anthos Service Mesh v1.11 から正式な管理ツールとなった <code>asmcli</code> をダウンロードします。</p><figure class=xCodeBlock><figcaption class=xCodeBlock_title>asmcliツールのダウンロード</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>curl https://storage.googleapis.com/csm-artifacts/asm/asmcli_1.11 &gt; asmcli
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 実行権限の付与</span>
</span></span><span style=display:flex><span>chmod +x asmcli</span></span></code></pre></div></div></figure><h3 id=gke-クラスタ-1-へのインストール>GKE クラスタ #1 へのインストール<a hidden class=anchor aria-hidden=true href=#gke-クラスタ-1-へのインストール>#</a></h3><p>まずは GKE クラスタ #1 に Anthos Service Mesh をインストールしていきましょう。Kubernetes API へ接続できるように GKE コントロールプレーンの承認済みネットワークに Cloud Shell の IP アドレスを登録し、<code>kubectl</code> を実行できるようにクラスタ認証情報を取得します。</p><figure class=xCodeBlock><figcaption class=xCodeBlock_title>クラスタ認証情報の取得(クラスタ#1)</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># CloudShellの承認済みネットワーク登録</span>
</span></span><span style=display:flex><span>gcloud container clusters update <span style=color:#e6db74>${</span>CLUSTER_1<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --region <span style=color:#e6db74>${</span>LOCATION<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --enable-master-authorized-networks <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --master-authorized-networks <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    <span style=color:#e6db74>&#34;</span><span style=color:#66d9ef>$(</span>dig +short myip.opendns.com @resolver1.opendns.com<span style=color:#66d9ef>)</span><span style=color:#e6db74>/32&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># クラスタ認証情報の取得</span>
</span></span><span style=display:flex><span>gcloud container clusters get-credentials <span style=color:#e6db74>${</span>CLUSTER_1<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --region <span style=color:#e6db74>${</span>LOCATION<span style=color:#e6db74>}</span></span></span></code></pre></div></div></figure><p>次に <code>asmcli</code> を使って Anthos Service Mesh をインストールします。コマンドが完了するまでおおよそ 5 分程度かかりました。</p><figure class=xCodeBlock><figcaption class=xCodeBlock_title>Anthos Service Meshのインストール(クラスタ#1)</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>./asmcli install <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --project_id <span style=color:#e6db74>${</span>PROJECT_ID<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --cluster_location <span style=color:#e6db74>${</span>LOCATION<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --cluster_name <span style=color:#e6db74>${</span>CLUSTER_1<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --managed <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --channel <span style=color:#e6db74>&#34;stable&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --enable-all <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --output_dir <span style=color:#e6db74>${</span>CLUSTER_1<span style=color:#e6db74>}</span></span></span></code></pre></div></div></figure><p>次のようなメッセージが出力されましたらインストールに成功です。</p><figure class=xCodeBlock><figcaption class=xCodeBlock_title>インストール成功時のメッセージ出力</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-txt data-lang=txt><span style=display:flex><span>asmcli: Successfully installed ASM.</span></span></code></pre></div></div></figure><h3 id=gke-クラスタ-2-へのインストール>GKE クラスタ #2 へのインストール<a hidden class=anchor aria-hidden=true href=#gke-クラスタ-2-へのインストール>#</a></h3><p>同様に GKE クラスタ #2 にも Anthos Service Mesh をインストールしましょう。</p><figure class=xCodeBlock><figcaption class=xCodeBlock_title>Anthos Service Meshのインストール(クラスタ#2)</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># CloudShellの承認済みネットワーク登録</span>
</span></span><span style=display:flex><span>gcloud container clusters update <span style=color:#e6db74>${</span>CLUSTER_2<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --region <span style=color:#e6db74>${</span>LOCATION<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --enable-master-authorized-networks <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --master-authorized-networks <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    <span style=color:#e6db74>&#34;</span><span style=color:#66d9ef>$(</span>dig +short myip.opendns.com @resolver1.opendns.com<span style=color:#66d9ef>)</span><span style=color:#e6db74>/32&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># クラスタ認証情報の取得</span>
</span></span><span style=display:flex><span>gcloud container clusters get-credentials <span style=color:#e6db74>${</span>CLUSTER_2<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --region <span style=color:#e6db74>${</span>LOCATION<span style=color:#e6db74>}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Anthos Service Mesh のインストール</span>
</span></span><span style=display:flex><span>./asmcli install <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --project_id <span style=color:#e6db74>${</span>PROJECT_ID<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --cluster_location <span style=color:#e6db74>${</span>LOCATION<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --cluster_name <span style=color:#e6db74>${</span>CLUSTER_2<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --managed <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --channel <span style=color:#e6db74>&#34;stable&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --enable-all <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --output_dir <span style=color:#e6db74>${</span>CLUSTER_2<span style=color:#e6db74>}</span></span></span></code></pre></div></div></figure><h3 id=ファイアウォールルールの更新-限定公開クラスタ時のみ>ファイアウォールルールの更新 (限定公開クラスタ時のみ)<a hidden class=anchor aria-hidden=true href=#ファイアウォールルールの更新-限定公開クラスタ時のみ>#</a></h3><p>限定公開クラスタに Anthos Service Mesh をインストールした場合は、コントロールプレーンからのポート 15017 による通信を追加で許可する必要があります。次のコマンド実行してコントロールプレーンからのポート 15017 による通信を許可します。</p><figure class=xCodeBlock><figcaption class=xCodeBlock_title>ファイアウォールルールの更新(限定公開クラスタ時のみ)</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 既存のファイアウォールルールに 15017/TCP の許可ルールを追加 (東京リージョン)</span>
</span></span><span style=display:flex><span>gcloud compute firewall-rules update <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    <span style=color:#66d9ef>$(</span>gcloud compute firewall-rules list <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>        --filter<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;name~</span><span style=color:#e6db74>${</span>CLUSTER_1<span style=color:#e6db74>}</span><span style=color:#e6db74>-.*-master&#34;</span> --format<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;value(name)&#34;</span><span style=color:#66d9ef>)</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --allow tcp:10250,tcp:443,tcp:15017
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 既存のファイアウォールルールに 15017/TCP の許可ルールを追加 (大阪リージョン)</span>
</span></span><span style=display:flex><span>gcloud compute firewall-rules update <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    <span style=color:#66d9ef>$(</span>gcloud compute firewall-rules list <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>        --filter<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;name~</span><span style=color:#e6db74>${</span>CLUSTER_2<span style=color:#e6db74>}</span><span style=color:#e6db74>-.*-master&#34;</span> --format<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;value(name)&#34;</span><span style=color:#66d9ef>)</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --allow tcp:10250,tcp:443,tcp:15017</span></span></code></pre></div></div></figure><h2 id=step4-マルチクラスタメッシュの設定>Step4. マルチクラスタメッシュの設定<a hidden class=anchor aria-hidden=true href=#step4-マルチクラスタメッシュの設定>#</a></h2><h3 id=クラスタ間通信の許可>クラスタ間通信の許可<a hidden class=anchor aria-hidden=true href=#クラスタ間通信の許可>#</a></h3><p>クラスタをまたがってのサービス間通信ができるように次のコマンドを実行してファイアウォールルール <code>"VPCネットワーク名"-istio-multicluster-pods</code> を新たに作成します。</p><figure class=xCodeBlock><figcaption class=xCodeBlock_title>クラスタ間通信の許可</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 環境変数の設定</span>
</span></span><span style=display:flex><span>CLUSTER_1_CIDR<span style=color:#f92672>=</span><span style=color:#66d9ef>$(</span>gcloud container clusters list <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --filter<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;name~</span><span style=color:#e6db74>${</span>CLUSTER_1<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span> --format<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;value(clusterIpv4Cidr)&#39;</span><span style=color:#66d9ef>)</span>
</span></span><span style=display:flex><span>CLUSTER_2_CIDR<span style=color:#f92672>=</span><span style=color:#66d9ef>$(</span>gcloud container clusters list <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --filter<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;name~</span><span style=color:#e6db74>${</span>CLUSTER_2<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span> --format<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;value(clusterIpv4Cidr)&#39;</span><span style=color:#66d9ef>)</span>
</span></span><span style=display:flex><span>CLUSTER_1_NETTAG<span style=color:#f92672>=</span><span style=color:#66d9ef>$(</span>gcloud compute instances list <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --filter<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;name~</span><span style=color:#e6db74>${</span>CLUSTER_1::20<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span> --format<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;value(tags.items.[0])&#39;</span> | <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    grep <span style=color:#e6db74>${</span>CLUSTER_1<span style=color:#e6db74>}</span> | sort -u<span style=color:#66d9ef>)</span>
</span></span><span style=display:flex><span>CLUSTER_2_NETTAG<span style=color:#f92672>=</span><span style=color:#66d9ef>$(</span>gcloud compute instances list <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --filter<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;name~</span><span style=color:#e6db74>${</span>CLUSTER_2::20<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span> --format<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;value(tags.items.[0])&#39;</span> | <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    grep <span style=color:#e6db74>${</span>CLUSTER_2<span style=color:#e6db74>}</span> | sort -u<span style=color:#66d9ef>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># クラスタ間通信を許可するファイアウォールルールの作成</span>
</span></span><span style=display:flex><span>gcloud compute firewall-rules create <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>NETWORK<span style=color:#e6db74>}</span><span style=color:#e6db74>-istio-multicluster-pods&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --network<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>NETWORK<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --allow<span style=color:#f92672>=</span>tcp,udp,icmp,esp,ah,sctp <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --direction<span style=color:#f92672>=</span>INGRESS <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --priority<span style=color:#f92672>=</span><span style=color:#ae81ff>900</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --source-ranges<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>CLUSTER_1_CIDR<span style=color:#e6db74>}</span><span style=color:#e6db74>,</span><span style=color:#e6db74>${</span>CLUSTER_2_CIDR<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --target-tags<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>CLUSTER_1_NETTAG<span style=color:#e6db74>}</span><span style=color:#e6db74>,</span><span style=color:#e6db74>${</span>CLUSTER_2_NETTAG<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span></span></span></code></pre></div></div></figure><h3 id=クラスタ間サービスディスカバリの設定>クラスタ間サービスディスカバリの設定<a hidden class=anchor aria-hidden=true href=#クラスタ間サービスディスカバリの設定>#</a></h3><p>次のコマンドを実行し、クラスタ間でサービスの自動検出ができるように <code>asmcli</code> を使って設定を行います。</p><figure class=xCodeBlock><figcaption class=xCodeBlock_title>クラスタ間サービスディスカバリの設定</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>./asmcli create-mesh <span style=color:#e6db74>${</span>PROJECT_ID<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    <span style=color:#e6db74>${</span>PROJECT_ID<span style=color:#e6db74>}</span>/<span style=color:#e6db74>${</span>LOCATION<span style=color:#e6db74>}</span>/<span style=color:#e6db74>${</span>CLUSTER_1<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    <span style=color:#e6db74>${</span>PROJECT_ID<span style=color:#e6db74>}</span>/<span style=color:#e6db74>${</span>LOCATION<span style=color:#e6db74>}</span>/<span style=color:#e6db74>${</span>CLUSTER_2<span style=color:#e6db74>}</span></span></span></code></pre></div></div></figure><h3 id=シークレット情報の更新-限定公開クラスタ時のみ>シークレット情報の更新 (限定公開クラスタ時のみ)<a hidden class=anchor aria-hidden=true href=#シークレット情報の更新-限定公開クラスタ時のみ>#</a></h3><p>限定公開クラスタで構築した場合は、Anthos Service Mesh コントロールプレーンから他の GKE クラスタコントロールプレーンへプライベートネットワーク経由でアクセスできるようにシークレット情報を書き換えましょう。</p><figure class=xCodeBlock><figcaption class=xCodeBlock_title>シークレット情報の更新(限定公開クラスタ時のみ)</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 環境変数の設定</span>
</span></span><span style=display:flex><span>CLUSTER_1_PRIV_IP<span style=color:#f92672>=</span><span style=color:#66d9ef>$(</span>gcloud container clusters describe <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>CLUSTER_1<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --region <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>LOCATION<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span> --format <span style=color:#e6db74>&#34;value(privateClusterConfig.privateEndpoint)&#34;</span><span style=color:#66d9ef>)</span>
</span></span><span style=display:flex><span>CLUSTER_2_PRIV_IP<span style=color:#f92672>=</span><span style=color:#66d9ef>$(</span>gcloud container clusters describe <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>CLUSTER_2<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --region <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>LOCATION<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span> --format <span style=color:#e6db74>&#34;value(privateClusterConfig.privateEndpoint)&#34;</span><span style=color:#66d9ef>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># プライベートエンドポイントに書き換えたシークレット情報の作成 (クラスタ#1)</span>
</span></span><span style=display:flex><span>./<span style=color:#e6db74>${</span>CLUSTER_1<span style=color:#e6db74>}</span>/istioctl x create-remote-secret <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --context<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>CTX_1<span style=color:#e6db74>}</span> --name<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>CLUSTER_1<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --server<span style=color:#f92672>=</span>https://<span style=color:#e6db74>${</span>CLUSTER_1_PRIV_IP<span style=color:#e6db74>}</span> &gt; <span style=color:#e6db74>${</span>CTX_1<span style=color:#e6db74>}</span>.secret
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># プライベートエンドポイントに書き換えたシークレット情報の作成 (クラスタ#2)</span>
</span></span><span style=display:flex><span>./<span style=color:#e6db74>${</span>CLUSTER_1<span style=color:#e6db74>}</span>/istioctl x create-remote-secret <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --context<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>CTX_2<span style=color:#e6db74>}</span> --name<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>CLUSTER_2<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    --server<span style=color:#f92672>=</span>https://<span style=color:#e6db74>${</span>CLUSTER_2_PRIV_IP<span style=color:#e6db74>}</span> &gt; <span style=color:#e6db74>${</span>CTX_2<span style=color:#e6db74>}</span>.secret
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># シークレット情報の更新 (クラスタ#1)</span>
</span></span><span style=display:flex><span>kubectl apply -f <span style=color:#e6db74>${</span>CTX_2<span style=color:#e6db74>}</span>.secret --context<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>CTX_1<span style=color:#e6db74>}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># シークレット情報の更新 (クラスタ#2)</span>
</span></span><span style=display:flex><span>kubectl apply -f <span style=color:#e6db74>${</span>CTX_1<span style=color:#e6db74>}</span>.secret --context<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>CTX_2<span style=color:#e6db74>}</span></span></span></code></pre></div></div></figure><p>ここまで終わりましたらクラスタ間で Kubernetes サービスがロードバランシングされるようになります。</p><h3 id=クラスタ間ロードバランシングの動作確認>クラスタ間ロードバランシングの動作確認<a hidden class=anchor aria-hidden=true href=#クラスタ間ロードバランシングの動作確認>#</a></h3><p>構築はまだ続きますがいったんこの状態で、Anthos Service Mesh をインストールした際に &ndash;output_dir で指定したディレクトリへ格納されているサンプルアプリケーションの中から HelloWorld と Sleep というアプリケーションを使用して、クラスタ間で負荷が分散されることを実際に確認していきたいと思います。サンプルアプリケーションの詳細につきましては次の URL をご参照ください。</p><p><a href=https://github.com/istio/istio/tree/master/samples>https://github.com/istio/istio/tree/master/samples</a></p><p>現時点では何もルーティング設定をしていないため、次の図のように 50% ずつトラフィックが振り分けられる状態を確認できるかと思います。</p><p><img loading=lazy src=images/02-check-simple-load-balancing.png alt=02-check-simple-load-balancing.png></p><h4 id=サンプルアプリケーションのデプロイ>サンプルアプリケーションのデプロイ<a hidden class=anchor aria-hidden=true href=#サンプルアプリケーションのデプロイ>#</a></h4><p>それではサンプルアプリケーションをデプロイしていきましょう。まずは次のコマンドでサンプルアプリケーション用の Namespace を新たに作成します。</p><figure class=xCodeBlock><figcaption class=xCodeBlock_title>サンプルアプリケーション用Namespaceの作成</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 環境変数の設定</span>
</span></span><span style=display:flex><span>export SAMPLE_NAMESPACE<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;sample&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 両クラスタにサンプルアプリケーション用 Namespace リソースの作成</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> CTX in <span style=color:#e6db74>${</span>CTX_1<span style=color:#e6db74>}</span> <span style=color:#e6db74>${</span>CTX_2<span style=color:#e6db74>}</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>do</span>
</span></span><span style=display:flex><span>    kubectl create --context<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>CTX<span style=color:#e6db74>}</span> namespace <span style=color:#e6db74>${</span>SAMPLE_NAMESPACE<span style=color:#e6db74>}</span>
</span></span><span style=display:flex><span>    kubectl label --context<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>CTX<span style=color:#e6db74>}</span> namespace <span style=color:#e6db74>${</span>SAMPLE_NAMESPACE<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>        istio.io/rev<span style=color:#f92672>=</span>asm-managed-stable --overwrite
</span></span><span style=display:flex><span><span style=color:#66d9ef>done</span></span></span></code></pre></div></div></figure><p>次に HelloWorld および Sleep アプリケーションをデプロイしましょう。どちらのクラスタ上の Pod に振り分けられたかをわかりやすくするため、クラスタ #1 に HelloWorld アプリケーションの v1、クラスタ #2 に v2 をデプロイしています。</p><figure class=xCodeBlock><figcaption class=xCodeBlock_title>サンプルアプリケーションのデプロイ</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 両クラスタに HelloWorld サービスのデプロイ</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> CTX in <span style=color:#e6db74>${</span>CTX_1<span style=color:#e6db74>}</span> <span style=color:#e6db74>${</span>CTX_2<span style=color:#e6db74>}</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>do</span>
</span></span><span style=display:flex><span>    kubectl apply --context<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>CTX<span style=color:#e6db74>}</span> -n <span style=color:#e6db74>${</span>SAMPLE_NAMESPACE<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>        -f <span style=color:#e6db74>${</span>CLUSTER_1<span style=color:#e6db74>}</span>/istio-1.11.2-asm.17/samples/helloworld/helloworld.yaml <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>        -l service<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;helloworld&#34;</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>done</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># クラスタ #1 に HelloWorld アプリケーションの v1 をデプロイ</span>
</span></span><span style=display:flex><span>kubectl apply --context<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>CTX_1<span style=color:#e6db74>}</span> -n <span style=color:#e6db74>${</span>SAMPLE_NAMESPACE<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    -f <span style=color:#e6db74>${</span>CLUSTER_1<span style=color:#e6db74>}</span>/istio-1.11.2-asm.17/samples/helloworld/helloworld.yaml <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    -l version<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;v1&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># クラスタ #2 に HelloWorld アプリケーションの v2 をデプロイ</span>
</span></span><span style=display:flex><span>kubectl apply --context<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>CTX_2<span style=color:#e6db74>}</span> -n <span style=color:#e6db74>${</span>SAMPLE_NAMESPACE<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    -f <span style=color:#e6db74>${</span>CLUSTER_1<span style=color:#e6db74>}</span>/istio-1.11.2-asm.17/samples/helloworld/helloworld.yaml <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    -l version<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;v2&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 両クラスタに Sleep サービス、アプリケーションのデプロイ</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> CTX in <span style=color:#e6db74>${</span>CTX_1<span style=color:#e6db74>}</span> <span style=color:#e6db74>${</span>CTX_2<span style=color:#e6db74>}</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>do</span>
</span></span><span style=display:flex><span>    kubectl apply --context<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>CTX<span style=color:#e6db74>}</span> -n <span style=color:#e6db74>${</span>SAMPLE_NAMESPACE<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>        -f <span style=color:#e6db74>${</span>CLUSTER_1<span style=color:#e6db74>}</span>/istio-1.11.2-asm.17/samples/sleep/sleep.yaml
</span></span><span style=display:flex><span><span style=color:#66d9ef>done</span></span></span></code></pre></div></div></figure><h4 id=サービス間通信の実行>サービス間通信の実行<a hidden class=anchor aria-hidden=true href=#サービス間通信の実行>#</a></h4><p>それでは Sleep アプリケーションから HelloWorld アプリケーションへのサービス間通信をしてみましょう。次のコマンドでは各クラスタ上の Sleep アプリケーションからそれぞれ 10 回ずつ HelloWorld サービスへの通信を実施しています。</p><figure class=xCodeBlock><figcaption class=xCodeBlock_title>サービス間通信の実行例</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#66d9ef>for</span> CTX in <span style=color:#e6db74>${</span>CTX_1<span style=color:#e6db74>}</span> <span style=color:#e6db74>${</span>CTX_2<span style=color:#e6db74>}</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>do</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> x in <span style=color:#e6db74>`</span>seq <span style=color:#ae81ff>1</span> 10<span style=color:#e6db74>`</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>do</span>
</span></span><span style=display:flex><span>        kubectl exec --context<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>CTX<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span> -n sample -c sleep <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>            <span style=color:#e6db74>&#34;</span><span style=color:#66d9ef>$(</span>kubectl get pod --context<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>CTX<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span> -n sample -l <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>            app<span style=color:#f92672>=</span>sleep -o jsonpath<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;{.items[0].metadata.name}&#39;</span><span style=color:#66d9ef>)</span><span style=color:#e6db74>&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>            -- curl -sS helloworld.<span style=color:#e6db74>${</span>SAMPLE_NAMESPACE<span style=color:#e6db74>}</span>:5000/hello
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>done</span>
</span></span><span style=display:flex><span>    echo <span style=color:#e6db74>&#39;---&#39;</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>done</span></span></span></code></pre></div></div></figure><p>次の出力例のように両クラスタから v1 と v2 の Pod へランダムで 50% ずつトラフィックが振り分けられる状態を確認できるかと思います。</p><figure class=xCodeBlock><figcaption class=xCodeBlock_title>メッセージ出力例</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-txt data-lang=txt><span style=display:flex><span>Hello version: v1, instance: helloworld-v1-776f57d5f6-62c9f
</span></span><span style=display:flex><span>Hello version: v1, instance: helloworld-v1-776f57d5f6-62c9f
</span></span><span style=display:flex><span>Hello version: v2, instance: helloworld-v2-54df5f84b-ffpmb
</span></span><span style=display:flex><span>:
</span></span><span style=display:flex><span>---
</span></span><span style=display:flex><span>:
</span></span><span style=display:flex><span>Hello version: v1, instance: helloworld-v1-776f57d5f6-62c9f
</span></span><span style=display:flex><span>Hello version: v2, instance: helloworld-v2-54df5f84b-ffpmb
</span></span><span style=display:flex><span>Hello version: v1, instance: helloworld-v1-776f57d5f6-62c9f</span></span></code></pre></div></div></figure><p>以上でクラスタ間ロードバランシングの動作確認は完了です。</p><h2 id=step5-高度なクラスタ間ロードバランシングの設定>Step5. 高度なクラスタ間ロードバランシングの設定<a hidden class=anchor aria-hidden=true href=#step5-高度なクラスタ間ロードバランシングの設定>#</a></h2><p>次にもう少し高度なクラスタ間ロードバランシングの設定をしていきましょう。ユースケースはいくつかありますが、今回は次の図のように GKE クラスタ #2 側の GKE クラスタのアップグレード後にアプリケーションの動作に影響がないかを少量のトラフィックを流して確認し、問題ないことを確認できたらその比重を段階的にあげていく、といったカナリアリリースのシナリオを想定した振り分け制御を行っていきたいと思います。</p><p><img loading=lazy src=images/03-canary.png alt=03-canary.png></p><h3 id=istio-リソースのデプロイ>Istio リソースのデプロイ<a hidden class=anchor aria-hidden=true href=#istio-リソースのデプロイ>#</a></h3><p>それでは設定していきましょう。まずは Istio VirtualService リソース<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>および Istio DestinationRule リソース<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>の定義ファイルを作成しましょう。例のように VirtualService リソースにサブセットごとの振り分けの重みづけを、DestinationRule リソースにサブセットの定義をします。</p><figure class=xCodeBlock><figcaption class=xCodeBlock_title>helloworld-virtualservice.yaml</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>networking.istio.io/v1alpha3</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>VirtualService</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>helloworld</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>hosts</span>:
</span></span><span style=display:flex><span>  - <span style=color:#ae81ff>helloworld</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>http</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>route</span>:
</span></span><span style=display:flex><span>    - <span style=color:#f92672>destination</span>:
</span></span><span style=display:flex><span>        <span style=color:#f92672>host</span>: <span style=color:#ae81ff>helloworld</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>subset</span>: <span style=color:#ae81ff>v1</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>weight</span>: <span style=color:#ae81ff>80</span>
</span></span><span style=display:flex><span>    - <span style=color:#f92672>destination</span>:
</span></span><span style=display:flex><span>        <span style=color:#f92672>host</span>: <span style=color:#ae81ff>helloworld</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>subset</span>: <span style=color:#ae81ff>v2</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>weight</span>: <span style=color:#ae81ff>20</span></span></span></code></pre></div></div></figure><figure class=xCodeBlock><figcaption class=xCodeBlock_title>helloworld-destinationrule.yaml</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>networking.istio.io/v1alpha3</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>DestinationRule</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>helloworld</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>host</span>: <span style=color:#ae81ff>helloworld</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>subsets</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>v1</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>labels</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>version</span>: <span style=color:#ae81ff>v1</span>
</span></span><span style=display:flex><span>  - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>v2</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>labels</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>version</span>: <span style=color:#ae81ff>v2</span></span></span></code></pre></div></div></figure><p>次のコマンドで両クラスタに Istio リソースをデプロイしましょう。これで設定は終わりです。</p><figure class=xCodeBlock><figcaption class=xCodeBlock_title>Istioリソースのデプロイ</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 両クラスタに VirtualService リソースをデプロイ</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> CTX in <span style=color:#e6db74>${</span>CTX_1<span style=color:#e6db74>}</span> <span style=color:#e6db74>${</span>CTX_2<span style=color:#e6db74>}</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>do</span>
</span></span><span style=display:flex><span>    kubectl apply --context<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>CTX<span style=color:#e6db74>}</span> -n <span style=color:#e6db74>${</span>SAMPLE_NAMESPACE<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>        -f helloworld-virtualservice.yaml
</span></span><span style=display:flex><span><span style=color:#66d9ef>done</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 両クラスタに DestinationRule リソースをデプロイ</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> CTX in <span style=color:#e6db74>${</span>CTX_1<span style=color:#e6db74>}</span> <span style=color:#e6db74>${</span>CTX_2<span style=color:#e6db74>}</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>do</span>
</span></span><span style=display:flex><span>    kubectl apply --context<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>CTX<span style=color:#e6db74>}</span> -n <span style=color:#e6db74>${</span>SAMPLE_NAMESPACE<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>        -f helloworld-destinationrule.yaml
</span></span><span style=display:flex><span><span style=color:#66d9ef>done</span></span></span></code></pre></div></div></figure><h3 id=カナリアリリースの動作確認>カナリアリリースの動作確認<a hidden class=anchor aria-hidden=true href=#カナリアリリースの動作確認>#</a></h3><p>構築はまだ続きますがいったんこの状態で、クラスタ間で負荷が設定どおりの比重で分散されることを実際に確認していきたいと思います。クラスタ間ロードバランシングの動作確認と同様に Sleep アプリケーションから HelloWorld アプリケーションへのサービス間通信をしてみましょう。</p><figure class=xCodeBlock><figcaption class=xCodeBlock_title>サービス間通信の実行例</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#66d9ef>for</span> x in <span style=color:#e6db74>`</span>seq <span style=color:#ae81ff>1</span> 10<span style=color:#e6db74>`</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>do</span>
</span></span><span style=display:flex><span>    kubectl exec --context<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>CTX_1<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span> -n sample -c sleep <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>        <span style=color:#e6db74>&#34;</span><span style=color:#66d9ef>$(</span>kubectl get pod --context<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>CTX_1<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span> -n sample -l <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>        app<span style=color:#f92672>=</span>sleep -o jsonpath<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;{.items[0].metadata.name}&#39;</span><span style=color:#66d9ef>)</span><span style=color:#e6db74>&#34;</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>        -- curl -sS helloworld.<span style=color:#e6db74>${</span>SAMPLE_NAMESPACE<span style=color:#e6db74>}</span>:5000/hello
</span></span><span style=display:flex><span><span style=color:#66d9ef>done</span></span></span></code></pre></div></div></figure><p>10 回の実行では試行回数が少ないため誤差はあるかと思いますが、出力例のように v1 への振り分けが約 80%、v2 への振り分けが約 20% となることが確認できるかと思います。</p><figure class=xCodeBlock><figcaption class=xCodeBlock_title>メッセージ出力例</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-txt data-lang=txt><span style=display:flex><span>Hello version: v1, instance: helloworld-v1-58d756cf5d-bs22v
</span></span><span style=display:flex><span>Hello version: v1, instance: helloworld-v1-58d756cf5d-bs22v
</span></span><span style=display:flex><span>Hello version: v2, instance: helloworld-v2-54df5f84b-ffpmb
</span></span><span style=display:flex><span>Hello version: v1, instance: helloworld-v1-58d756cf5d-bs22v
</span></span><span style=display:flex><span>Hello version: v1, instance: helloworld-v1-58d756cf5d-bs22v
</span></span><span style=display:flex><span>Hello version: v1, instance: helloworld-v1-58d756cf5d-bs22v
</span></span><span style=display:flex><span>Hello version: v1, instance: helloworld-v1-58d756cf5d-bs22v
</span></span><span style=display:flex><span>Hello version: v2, instance: helloworld-v2-54df5f84b-ffpmb
</span></span><span style=display:flex><span>Hello version: v1, instance: helloworld-v1-58d756cf5d-bs22v
</span></span><span style=display:flex><span>Hello version: v1, instance: helloworld-v1-58d756cf5d-bs22v</span></span></code></pre></div></div></figure><p>以上で少し高度なクラスタ間ロードバランシング設定の動作確認もできました。</p><h2 id=step6-ingress-ゲートウェイの設定>Step6. Ingress ゲートウェイの設定<a hidden class=anchor aria-hidden=true href=#step6-ingress-ゲートウェイの設定>#</a></h2><p>さてここからは話題がガラッと変わり、メッシュの外からの通信を受け入れるための Ingress ゲートウェイの設定をしていきたいと思います。今回は次の図のように各クラスタに配置された Ingress ゲートウェイアプリケーションを束ねるようにマルチクラスタ Ingress およびマルチクラスタ Service を配置する構成を作っていきます。</p><p><img loading=lazy src=images/04-multi-cluster-ingress.png alt=04-multi-cluster-ingress.png></p><h3 id=マルチクラスタ-ingress-機能の有効化>マルチクラスタ Ingress 機能の有効化<a hidden class=anchor aria-hidden=true href=#マルチクラスタ-ingress-機能の有効化>#</a></h3><p>最初に次のコマンドを実行し、マルチクラスタ Ingress 機能を有効化しましょう。なお、今回はマルチクラスタ Ingress の設定を行うメインの GKE クラスタ(=構成クラスタ)として、GKE クラスタ #1 を登録しています。</p><figure class=xCodeBlock><figcaption class=xCodeBlock_title>マルチクラスタIngress機能の有効化</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>gcloud container hub ingress enable <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>  --config-membership<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>CLUSTER_1<span style=color:#e6db74>}</span></span></span></code></pre></div></div></figure><h3 id=ingress-ゲートウェイ定義ファイルの作成>Ingress ゲートウェイ定義ファイルの作成<a hidden class=anchor aria-hidden=true href=#ingress-ゲートウェイ定義ファイルの作成>#</a></h3><p>今回は Anthos Service Mesh をインストールした際に <code>--output_dir</code> で指定したディレクトリへ Ingress ゲートウェイのサンプル定義ファイルが配置されているのでこちらをベースに作成していきたいと思います。まずはサンプル定義ファイルを複製し、マルチクラスタ Ingress 構成向けに MultiClusterService<sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup>、BackendConfig<sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup>、MultiClusterIngress<sup id=fnref:5><a href=#fn:5 class=footnote-ref role=doc-noteref>5</a></sup> の 3 種類のリソース定義ファイルを追加していきましょう。</p><figure class=xCodeBlock><figcaption class=xCodeBlock_title>Ingressゲートウェイ定義ファイルの作成準備</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># サンプル定義ファイルを複製</span>
</span></span><span style=display:flex><span>cp -r <span style=color:#e6db74>${</span>CLUSTER_1<span style=color:#e6db74>}</span>/samples/gateways/istio-ingressgateway .
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># マルチクラスタ Ingress 定義ファイルを格納するディレクトリを作成</span>
</span></span><span style=display:flex><span>mkdir -p istio-ingressgateway/multicluster
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Service リソース定義から MultiClusterService リソース定義ファイルに書き換え</span>
</span></span><span style=display:flex><span>mv istio-ingressgateway/service.yaml istio-ingressgateway/multicluster/multiclusterservice.yaml
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 新たな定義ファイルを 2 種類作成</span>
</span></span><span style=display:flex><span>touch istio-ingressgateway/multicluster/backendconfig.yaml
</span></span><span style=display:flex><span>touch istio-ingressgateway/multicluster/multiclusteringress.yaml</span></span></code></pre></div></div></figure><p>それでは MultiClusterService<sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup>、BackendConfig<sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup>、MultiClusterIngress<sup id=fnref:5><a href=#fn:5 class=footnote-ref role=doc-noteref>5</a></sup> の 3 種類のリソース定義ファイルを編集していきましょう。MultiClusterService は Service リソースをマルチクラスタに対応させたリソースという位置づけのため、基本的に Service リソースの設定値とほぼ変わりません。今回は Ingress をフロントに配置するので LoadBalancer タイプの定義を削除し、デフォルトの Cluster IP に変更しています。</p><figure class=xCodeBlock><figcaption class=xCodeBlock_title>istio-ingressgateway/multicluster/multiclusterservice.yaml（差分）</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-diff data-lang=diff><span style=display:flex><span><span style=color:#f92672>- apiVersion: v1
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+ apiVersion: networking.gke.io/v1
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span><span style=color:#f92672>- kind: Service
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+ kind: MultiClusterService
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span>  metadata:
</span></span><span style=display:flex><span>    name: istio-ingressgateway
</span></span><span style=display:flex><span><span style=color:#a6e22e>+   annotations:
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+     cloud.google.com/backend-config: &#39;{&#34;default&#34;: &#34;ingress-backendconfig&#34;}&#39;
</span></span></span><span style=display:flex><span><span style=color:#a6e22e></span>    labels:
</span></span><span style=display:flex><span>      app: istio-ingressgateway
</span></span><span style=display:flex><span>      istio: ingressgateway
</span></span><span style=display:flex><span>  spec:
</span></span><span style=display:flex><span><span style=color:#f92672>-   ports:
</span></span></span><span style=display:flex><span><span style=color:#f92672>-   # status-port exposes a /healthz/ready endpoint that can be used with GKE Ingress health checks
</span></span></span><span style=display:flex><span><span style=color:#f92672>-   - name: status-port
</span></span></span><span style=display:flex><span><span style=color:#f92672>-     port: 15021
</span></span></span><span style=display:flex><span><span style=color:#f92672>-     protocol: TCP
</span></span></span><span style=display:flex><span><span style=color:#f92672>-     targetPort: 15021
</span></span></span><span style=display:flex><span><span style=color:#f92672>-   # Any ports exposed in Gateway resources should be exposed here.
</span></span></span><span style=display:flex><span><span style=color:#f92672>-   - name: http2
</span></span></span><span style=display:flex><span><span style=color:#f92672>-     port: 80
</span></span></span><span style=display:flex><span><span style=color:#f92672>-   - name: https
</span></span></span><span style=display:flex><span><span style=color:#f92672>-     port: 443
</span></span></span><span style=display:flex><span><span style=color:#f92672>-   selector:
</span></span></span><span style=display:flex><span><span style=color:#f92672>-     istio: ingressgateway
</span></span></span><span style=display:flex><span><span style=color:#f92672>-     app: istio-ingressgateway
</span></span></span><span style=display:flex><span><span style=color:#f92672>-   type: LoadBalancer
</span></span></span><span style=display:flex><span><span style=color:#f92672></span><span style=color:#a6e22e>+   template:
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+     spec:
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+       ports:
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+       # status-port exposes a /healthz/ready endpoint that can be used with GKE Ingress health checks
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+       - name: status-port
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+         port: 15021
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+         protocol: TCP
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+         targetPort: 15021
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+       # Any ports exposed in Gateway resources should be exposed here.
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+       - name: http2
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+         port: 80
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+       - name: https
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+         port: 443
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+       selector:
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+         istio: ingressgateway
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+         app: istio-ingressgateway
</span></span></span></code></pre></div></div></figure><p>BackendConfig リソースではバックエンドサービスである Ingress ゲートウェイアプリケーションのヘルスチェックに関する定義を記載します。Ingress ゲートウェイはヘルスチェック用パスとして /healthz/ready:15021 を用意しているため、こちらを設定しましょう。</p><figure class=xCodeBlock><figcaption class=xCodeBlock_title>istio-ingressgateway/multicluster/backendconfig.yaml（差分）</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-diff data-lang=diff><span style=display:flex><span><span style=color:#a6e22e>+ apiVersion: cloud.google.com/v1
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+ kind: BackendConfig
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+ metadata:
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+   name: ingress-backendconfig
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+ spec:
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+   healthCheck:
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+     requestPath: /healthz/ready
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+     port: 15021
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+     type: HTTP
</span></span></span></code></pre></div></div></figure><p>MultiClusterIngress は Ingress リソースをマルチクラスタに対応させたリソースという位置づけであり、基本的に Ingress リソースを定義するときと設定値はほぼ同じです。</p><figure class=xCodeBlock><figcaption class=xCodeBlock_title>istio-ingressgateway/multicluster/multiclusteringress.yaml（差分）</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-diff data-lang=diff><span style=display:flex><span><span style=color:#a6e22e>+ apiVersion: networking.gke.io/v1beta1
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+ kind: MultiClusterIngress
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+ metadata:
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+   name: istio-ingressgateway
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+   labels:
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+     app: istio-ingressgateway
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+     istio: ingressgateway
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+ spec:
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+   template:
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+     spec:
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+       backend:
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+         serviceName: istio-ingressgateway
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+         servicePort: 80
</span></span></span></code></pre></div></div></figure><h3 id=ingress-ゲートウェイのデプロイ>Ingress ゲートウェイのデプロイ<a hidden class=anchor aria-hidden=true href=#ingress-ゲートウェイのデプロイ>#</a></h3><p>まずは Ingress ゲートウェイリソースをデプロイする Namespace を新たに作成します。今回の例では <code>istio-gateway</code> という名前の Namespace を作成しています。</p><figure class=xCodeBlock><figcaption class=xCodeBlock_title>Ingress Gateway用のNamespace作成</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># 環境変数の設定</span>
</span></span><span style=display:flex><span>export GATEWAY_NAMESPACE<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;istio-gateway&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 両クラスタにサンプルアプリケーション用 Namespace リソースの作成</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> CTX in <span style=color:#e6db74>${</span>CTX_1<span style=color:#e6db74>}</span> <span style=color:#e6db74>${</span>CTX_2<span style=color:#e6db74>}</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>do</span>
</span></span><span style=display:flex><span>    kubectl create --context<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>CTX<span style=color:#e6db74>}</span> namespace <span style=color:#e6db74>${</span>GATEWAY_NAMESPACE<span style=color:#e6db74>}</span>
</span></span><span style=display:flex><span>    kubectl label --context<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>CTX<span style=color:#e6db74>}</span> namespace <span style=color:#e6db74>${</span>GATEWAY_NAMESPACE<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>        istio.io/rev<span style=color:#f92672>=</span>asm-managed-stable --overwrite
</span></span><span style=display:flex><span><span style=color:#66d9ef>done</span></span></span></code></pre></div></div></figure><p>次のコマンドを実行して Ingress ゲートウェイアプリケーションを両クラスタにデプロイしましょう。</p><figure class=xCodeBlock><figcaption class=xCodeBlock_title>Ingress Gatewayアプリケーションのデプロイ</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#66d9ef>for</span> CTX in <span style=color:#e6db74>${</span>CTX_1<span style=color:#e6db74>}</span> <span style=color:#e6db74>${</span>CTX_2<span style=color:#e6db74>}</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>do</span>
</span></span><span style=display:flex><span>    kubectl apply -n <span style=color:#e6db74>${</span>GATEWAY_NAMESPACE<span style=color:#e6db74>}</span>  --context<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>CTX<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>        -f istio-ingressgateway
</span></span><span style=display:flex><span><span style=color:#66d9ef>done</span></span></span></code></pre></div></div></figure><p>最後にマルチクラスタ Ingress リソースを構成クラスタである GKE クラスタ #1 に対してデプロイをしましょう。</p><figure class=xCodeBlock><figcaption class=xCodeBlock_title>Ingress Gatewayアプリケーションのデプロイ</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl apply -n <span style=color:#e6db74>${</span>GATEWAY_NAMESPACE<span style=color:#e6db74>}</span>  --context<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>CTX_1<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    -f istio-ingressgateway/multicluster</span></span></code></pre></div></div></figure><p>以上で Ingress ゲートウェイのデプロイは終わりです。</p><h3 id=istio-リソースのデプロイ-1>Istio リソースのデプロイ<a hidden class=anchor aria-hidden=true href=#istio-リソースのデプロイ-1>#</a></h3><p>Ingress ゲートウェイを通じてメッシュの外から HelloWorld アプリケーションへ通信ができるように Istio リソースの定義を行っていきたいと思います。まずは Istio Gateway リソース<sup id=fnref:6><a href=#fn:6 class=footnote-ref role=doc-noteref>6</a></sup>および Istio VirtualService リソース<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>の定義ファイルを作成しましょう。例のように Gateway リソースにメッシュ外から受け付けるポートとプロトコルを定義し、VirtualService リソースには Gateway に入ってきた通信のパターンマッチ条件と振り分け先バックエンドの指定をします。</p><figure class=xCodeBlock><figcaption class=xCodeBlock_title>helloworld-gateway.yaml</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>networking.istio.io/v1alpha3</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>Gateway</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>helloworld-gateway</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>selector</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>istio</span>: <span style=color:#ae81ff>ingressgateway</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>servers</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>port</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>number</span>: <span style=color:#ae81ff>80</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>name</span>: <span style=color:#ae81ff>http</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>protocol</span>: <span style=color:#ae81ff>HTTP</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>hosts</span>:
</span></span><span style=display:flex><span>    - <span style=color:#e6db74>&#34;*&#34;</span>
</span></span><span style=display:flex><span>---
</span></span><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>networking.istio.io/v1alpha3</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>VirtualService</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>helloworld-gateway</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>hosts</span>:
</span></span><span style=display:flex><span>  - <span style=color:#e6db74>&#34;*&#34;</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>gateways</span>:
</span></span><span style=display:flex><span>  - <span style=color:#ae81ff>helloworld-gateway</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>http</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>match</span>:
</span></span><span style=display:flex><span>    - <span style=color:#f92672>uri</span>:
</span></span><span style=display:flex><span>        <span style=color:#f92672>exact</span>: <span style=color:#ae81ff>/hello</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>route</span>:
</span></span><span style=display:flex><span>    - <span style=color:#f92672>destination</span>:
</span></span><span style=display:flex><span>        <span style=color:#f92672>host</span>: <span style=color:#ae81ff>helloworld</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>port</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>number</span>: <span style=color:#ae81ff>5000</span></span></span></code></pre></div></div></figure><p>次のコマンドで両クラスタに Istio リソースをデプロイし、アプリケーションへのインバウンド通信ができるように設定しましょう。</p><figure class=xCodeBlock><figcaption class=xCodeBlock_title>Istioリソースのデプロイ</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#66d9ef>for</span> CTX in <span style=color:#e6db74>${</span>CTX_1<span style=color:#e6db74>}</span> <span style=color:#e6db74>${</span>CTX_2<span style=color:#e6db74>}</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>do</span>
</span></span><span style=display:flex><span>    kubectl apply -n <span style=color:#e6db74>${</span>SAMPLE_NAMESPACE<span style=color:#e6db74>}</span> --context<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>CTX<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>        -f helloworld-gateway.yaml
</span></span><span style=display:flex><span><span style=color:#66d9ef>done</span></span></span></code></pre></div></div></figure><p>以上でメッシュ外からのアプリケーションへのインバウンド通信もできるようになりました。</p><h3 id=インバウンド通信の動作確認>インバウンド通信の動作確認<a hidden class=anchor aria-hidden=true href=#インバウンド通信の動作確認>#</a></h3><p>それではメッシュ外からのアプリケーションへのインバウンド通信ができることを確認していきましょう。実行例のように Ingress ゲートウェイの外部 IP アドレスに対して <code>curl</code> コマンドを実行し、アクセスをしてみましょう。</p><figure class=xCodeBlock><figcaption class=xCodeBlock_title>インバウンド通信の実行</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># Ingress ゲートウェイの外部 IP アドレスの取得</span>
</span></span><span style=display:flex><span>INGRESS_GATEWAY_IP<span style=color:#f92672>=</span><span style=color:#66d9ef>$(</span>kubectl --context<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>CTX_1<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    -n <span style=color:#e6db74>${</span>GATEWAY_NAMESPACE<span style=color:#e6db74>}</span> get MultiClusterIngress <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    -o custom-columns<span style=color:#f92672>=</span>VIP:status.VIP --no-headers<span style=color:#66d9ef>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> x in <span style=color:#e6db74>`</span>seq <span style=color:#ae81ff>1</span> 10<span style=color:#e6db74>`</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>do</span>
</span></span><span style=display:flex><span>    curl http://<span style=color:#e6db74>${</span>INGRESS_GATEWAY_IP<span style=color:#e6db74>}</span>/hello
</span></span><span style=display:flex><span><span style=color:#66d9ef>done</span></span></span></code></pre></div></div></figure><p>次の出力例のように両クラスタから v1 と v2 の Pod へランダムで 50% ずつトラフィックが振り分けられる状態を確認できるかと思います。</p><figure class=xCodeBlock><figcaption class=xCodeBlock_title>メッセージ出力例</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-txt data-lang=txt><span style=display:flex><span>Hello version: v1, instance: helloworld-v1-58d756cf5d-bs22v
</span></span><span style=display:flex><span>Hello version: v2, instance: helloworld-v2-54df5f84b-ffpmb
</span></span><span style=display:flex><span>Hello version: v1, instance: helloworld-v1-58d756cf5d-bs22v
</span></span><span style=display:flex><span>Hello version: v2, instance: helloworld-v2-54df5f84b-ffpmb
</span></span><span style=display:flex><span>Hello version: v2, instance: helloworld-v2-54df5f84b-ffpmb
</span></span><span style=display:flex><span>Hello version: v1, instance: helloworld-v1-58d756cf5d-bs22v
</span></span><span style=display:flex><span>Hello version: v1, instance: helloworld-v1-58d756cf5d-bs22v
</span></span><span style=display:flex><span>Hello version: v1, instance: helloworld-v1-58d756cf5d-bs22v
</span></span><span style=display:flex><span>Hello version: v2, instance: helloworld-v2-54df5f84b-ffpmb
</span></span><span style=display:flex><span>Hello version: v2, instance: helloworld-v2-54df5f84b-ffpmb</span></span></code></pre></div></div></figure><h2 id=step7-インバウンド通信に対する高度なロードバランシングの設定>Step7. インバウンド通信に対する高度なロードバランシングの設定<a hidden class=anchor aria-hidden=true href=#step7-インバウンド通信に対する高度なロードバランシングの設定>#</a></h2><p>メッシュの外からアプリケーションへのインバウンド通信に対する高度なロードバランシングの設定をしていきましょう。今回は Step5 のときとは逆に 80% を v2、20% を v1 に割り振るように設定していきたいと思います。</p><p><img loading=lazy src=images/05-inbound-canary.png alt=05-inbound-canary.png></p><h3 id=istio-リソースの更新>Istio リソースの更新<a hidden class=anchor aria-hidden=true href=#istio-リソースの更新>#</a></h3><p>それでは先ほど作成した Istio リソース定義ファイル <code>helloworld-gateway.yaml</code> の VirtualService リソース部分を編集し、サブセットごとの振り分け比重の定義を追加します。なお、サブセットの定義(DestinationRule リソース)については「Step5. 高度なクラスタ間ロードバランシングの設定」にて設定済みとなりますのでここでは省略します。</p><figure class=xCodeBlock><figcaption class=xCodeBlock_title>helloworld-gateway.yaml（差分）</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-diff data-lang=diff><span style=display:flex><span>  apiVersion: networking.istio.io/v1alpha3
</span></span><span style=display:flex><span>  kind: VirtualService
</span></span><span style=display:flex><span>  metadata:
</span></span><span style=display:flex><span>    name: helloworld-gateway
</span></span><span style=display:flex><span>  spec:
</span></span><span style=display:flex><span>    hosts:
</span></span><span style=display:flex><span>    - &#34;*&#34;
</span></span><span style=display:flex><span>    gateways:
</span></span><span style=display:flex><span>    - helloworld-gateway
</span></span><span style=display:flex><span>    http:
</span></span><span style=display:flex><span>    - match:
</span></span><span style=display:flex><span>      - uri:
</span></span><span style=display:flex><span>          exact: /hello
</span></span><span style=display:flex><span>      route:
</span></span><span style=display:flex><span>      - destination:
</span></span><span style=display:flex><span>          host: helloworld
</span></span><span style=display:flex><span>          port:
</span></span><span style=display:flex><span>            number: 5000
</span></span><span style=display:flex><span><span style=color:#a6e22e>+         subset: v1
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+       weight: 20
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+     - destination:
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+         host: helloworld
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+         port:
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+           number: 5000
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+         subset: v2
</span></span></span><span style=display:flex><span><span style=color:#a6e22e>+       weight: 80
</span></span></span></code></pre></div></div></figure><p>それでは次のコマンドで Istio リソースを更新しましょう。これで設定は終わりです。</p><figure class=xCodeBlock><figcaption class=xCodeBlock_title>Istioリソースの更新</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#66d9ef>for</span> CTX in <span style=color:#e6db74>${</span>CTX_1<span style=color:#e6db74>}</span> <span style=color:#e6db74>${</span>CTX_2<span style=color:#e6db74>}</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>do</span>
</span></span><span style=display:flex><span>    kubectl apply -n <span style=color:#e6db74>${</span>SAMPLE_NAMESPACE<span style=color:#e6db74>}</span> --context<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>CTX<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>        -f helloworld-gateway.yaml
</span></span><span style=display:flex><span><span style=color:#66d9ef>done</span></span></span></code></pre></div></div></figure><h3 id=カナリアリリースの動作確認-1>カナリアリリースの動作確認<a hidden class=anchor aria-hidden=true href=#カナリアリリースの動作確認-1>#</a></h3><p>それでは HelloWorld アプリケーションへの振り分けが設定どおりの比重で分散されることを実際に確認していきたいと思います。実行例のように Ingress ゲートウェイの外部 IP アドレスに対して curl コマンドを実行し、アクセスをしてみましょう。</p><figure class=xCodeBlock><figcaption class=xCodeBlock_title>インバウンド通信の実行</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># Ingress ゲートウェイの外部 IP アドレスの取得</span>
</span></span><span style=display:flex><span>INGRESS_GATEWAY_IP<span style=color:#f92672>=</span><span style=color:#66d9ef>$(</span>kubectl --context<span style=color:#f92672>=</span><span style=color:#e6db74>${</span>CTX_1<span style=color:#e6db74>}</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    -n <span style=color:#e6db74>${</span>GATEWAY_NAMESPACE<span style=color:#e6db74>}</span> get MultiClusterIngress <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>    -o custom-columns<span style=color:#f92672>=</span>VIP:status.VIP --no-headers<span style=color:#66d9ef>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> x in <span style=color:#e6db74>`</span>seq <span style=color:#ae81ff>1</span> 10<span style=color:#e6db74>`</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>do</span>
</span></span><span style=display:flex><span>    curl http://<span style=color:#e6db74>${</span>INGRESS_GATEWAY_IP<span style=color:#e6db74>}</span>/hello
</span></span><span style=display:flex><span><span style=color:#66d9ef>done</span></span></span></code></pre></div></div></figure><p>10 回の実行では試行回数が少ないため誤差はあるかと思いますが、出力例のように v1 への振り分けが約 20%、v2 への振り分けが約 80% となることが確認できるかと思います。</p><figure class=xCodeBlock><figcaption class=xCodeBlock_title>メッセージ出力例</figcaption><div class=xCodeBlock_code><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-txt data-lang=txt><span style=display:flex><span>Hello version: v2, instance: helloworld-v2-54df5f84b-ffpmb
</span></span><span style=display:flex><span>Hello version: v2, instance: helloworld-v2-54df5f84b-ffpmb
</span></span><span style=display:flex><span>Hello version: v2, instance: helloworld-v2-54df5f84b-ffpmb
</span></span><span style=display:flex><span>Hello version: v2, instance: helloworld-v2-54df5f84b-ffpmb
</span></span><span style=display:flex><span>Hello version: v2, instance: helloworld-v2-54df5f84b-ffpmb
</span></span><span style=display:flex><span>Hello version: v2, instance: helloworld-v2-54df5f84b-ffpmb
</span></span><span style=display:flex><span>Hello version: v1, instance: helloworld-v1-58d756cf5d-bs22v
</span></span><span style=display:flex><span>Hello version: v1, instance: helloworld-v1-58d756cf5d-bs22v
</span></span><span style=display:flex><span>Hello version: v2, instance: helloworld-v2-54df5f84b-ffpmb
</span></span><span style=display:flex><span>Hello version: v2, instance: helloworld-v2-54df5f84b-ffpmb</span></span></code></pre></div></div></figure><p>以上でメッシュの外からアプリケーションへのインバウンド通信に対する高度なロードバランシングの動作確認も終了です。お疲れ様でした。</p><h1 id=終わりに>終わりに<a hidden class=anchor aria-hidden=true href=#終わりに>#</a></h1><p>今回は単一リージョンに展開した複数 GKE クラスタを単一の Anthos Service Mesh 環境に追加し、GKE クラスタ間で負荷分散を行う方法についてご紹介でしたがいかがだったでしょうか。</p><p>複数 GKE クラスタでマルチクラスタメッシュを構築することにより、片方の GKE クラスタを先にバージョンアップし、サービスメッシュのトラフィック制御を使ってバージョンアップしたクラスタ側に少量のトラフィックを流して問題がないことを確認しながら段階的に比重をあげていく、といった「基盤部分も含めたカナリアリリース」のユースケースも容易に実現できるようになる見込みです。もしこれから Anthos Service Mesh 環境の利用を検討している方はマルチクラスタメッシュ構成についても検討してみてはいかがでしょうか。</p><hr><ul><li>Google Cloud は、Google LLC の商標または登録商標です。</li><li>その他、記載されている会社名および商品・製品・サービス名は、各社の商標または登録商標です。</li></ul><section class=footnotes role=doc-endnotes><hr><ol><li id=fn:1 role=doc-endnote><p>VirtualService はトラフィックの振り分け、ルーティングを定義する Istio リソース&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2 role=doc-endnote><p>DestinationRule は転送先サービスのサブセット化や各種トラフィックポリシーを定義する Istio リソース&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3 role=doc-endnote><p>MultiClusterService は Service リソースを複数のクラスタ上に展開する GKE 独自のカスタムリソース&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4 role=doc-endnote><p>BackendConfig はバックエンドサービスのヘルスチェックを定義する GKE 独自のカスタムリソース&#160;<a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:5 role=doc-endnote><p>MultiClusterIngress はマルチクラスタに対応した Ingress リソースを定義する GKE 独自のカスタムリソース&#160;<a href=#fnref:5 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:6 role=doc-endnote><p>Gateway は Ingress/Egress ゲートウェイで受け付けるポート、プロトコルを定義する Istio リソース&#160;<a href=#fnref:6 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></section></div><footer class=post-footer><ul class=post-tags><li><a href=https://chacco38.github.io/tags/google-cloud/>Google Cloud</a></li><li><a href=https://chacco38.github.io/tags/google-kubernetes-enginegke/>Google Kubernetes Engine(GKE)</a></li><li><a href=https://chacco38.github.io/tags/anthos-service-mesh/>Anthos Service Mesh</a></li><li><a href=https://chacco38.github.io/tags/kubernetes/>Kubernetes</a></li><li><a href=https://chacco38.github.io/tags/istio/>Istio</a></li></ul><nav class=paginav><a class=prev href=https://chacco38.github.io/posts/2021/12/aws-load-balancer-controller/><span class=title>« Prev Page</span><br><span>AWS Load Balancer Controller を使って ELB を Kubernetes のマニフェストファイルで管理しよう</span></a>
<a class=next href=https://chacco38.github.io/posts/2021/12/gcp-multi-region-asm-cluster/><span class=title>Next Page »</span><br><span>複数リージョンの GKE クラスタと Anthos Service Mesh でマルチクラスタメッシュ環境を構築してみた</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share 単一リージョンの複数 GKE クラスタと Anthos Service Mesh でマルチクラスタメッシュ環境を構築してみた on twitter" href="https://twitter.com/intent/tweet/?text=%e5%8d%98%e4%b8%80%e3%83%aa%e3%83%bc%e3%82%b8%e3%83%a7%e3%83%b3%e3%81%ae%e8%a4%87%e6%95%b0%20GKE%20%e3%82%af%e3%83%a9%e3%82%b9%e3%82%bf%e3%81%a8%20Anthos%20Service%20Mesh%20%e3%81%a7%e3%83%9e%e3%83%ab%e3%83%81%e3%82%af%e3%83%a9%e3%82%b9%e3%82%bf%e3%83%a1%e3%83%83%e3%82%b7%e3%83%a5%e7%92%b0%e5%a2%83%e3%82%92%e6%a7%8b%e7%af%89%e3%81%97%e3%81%a6%e3%81%bf%e3%81%9f&url=https%3a%2f%2fchacco38.github.io%2fposts%2f2021%2f12%2fgcp-multi-asm-cluster%2f&hashtags=GoogleCloud%2cGoogleKubernetesEngine%28GKE%29%2cAnthosServiceMesh%2cKubernetes%2cIstio"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 単一リージョンの複数 GKE クラスタと Anthos Service Mesh でマルチクラスタメッシュ環境を構築してみた on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fchacco38.github.io%2fposts%2f2021%2f12%2fgcp-multi-asm-cluster%2f&title=%e5%8d%98%e4%b8%80%e3%83%aa%e3%83%bc%e3%82%b8%e3%83%a7%e3%83%b3%e3%81%ae%e8%a4%87%e6%95%b0%20GKE%20%e3%82%af%e3%83%a9%e3%82%b9%e3%82%bf%e3%81%a8%20Anthos%20Service%20Mesh%20%e3%81%a7%e3%83%9e%e3%83%ab%e3%83%81%e3%82%af%e3%83%a9%e3%82%b9%e3%82%bf%e3%83%a1%e3%83%83%e3%82%b7%e3%83%a5%e7%92%b0%e5%a2%83%e3%82%92%e6%a7%8b%e7%af%89%e3%81%97%e3%81%a6%e3%81%bf%e3%81%9f&summary=%e5%8d%98%e4%b8%80%e3%83%aa%e3%83%bc%e3%82%b8%e3%83%a7%e3%83%b3%e3%81%ae%e8%a4%87%e6%95%b0%20GKE%20%e3%82%af%e3%83%a9%e3%82%b9%e3%82%bf%e3%81%a8%20Anthos%20Service%20Mesh%20%e3%81%a7%e3%83%9e%e3%83%ab%e3%83%81%e3%82%af%e3%83%a9%e3%82%b9%e3%82%bf%e3%83%a1%e3%83%83%e3%82%b7%e3%83%a5%e7%92%b0%e5%a2%83%e3%82%92%e6%a7%8b%e7%af%89%e3%81%97%e3%81%a6%e3%81%bf%e3%81%9f&source=https%3a%2f%2fchacco38.github.io%2fposts%2f2021%2f12%2fgcp-multi-asm-cluster%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 単一リージョンの複数 GKE クラスタと Anthos Service Mesh でマルチクラスタメッシュ環境を構築してみた on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fchacco38.github.io%2fposts%2f2021%2f12%2fgcp-multi-asm-cluster%2f&title=%e5%8d%98%e4%b8%80%e3%83%aa%e3%83%bc%e3%82%b8%e3%83%a7%e3%83%b3%e3%81%ae%e8%a4%87%e6%95%b0%20GKE%20%e3%82%af%e3%83%a9%e3%82%b9%e3%82%bf%e3%81%a8%20Anthos%20Service%20Mesh%20%e3%81%a7%e3%83%9e%e3%83%ab%e3%83%81%e3%82%af%e3%83%a9%e3%82%b9%e3%82%bf%e3%83%a1%e3%83%83%e3%82%b7%e3%83%a5%e7%92%b0%e5%a2%83%e3%82%92%e6%a7%8b%e7%af%89%e3%81%97%e3%81%a6%e3%81%bf%e3%81%9f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 単一リージョンの複数 GKE クラスタと Anthos Service Mesh でマルチクラスタメッシュ環境を構築してみた on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fchacco38.github.io%2fposts%2f2021%2f12%2fgcp-multi-asm-cluster%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 単一リージョンの複数 GKE クラスタと Anthos Service Mesh でマルチクラスタメッシュ環境を構築してみた on whatsapp" href="https://api.whatsapp.com/send?text=%e5%8d%98%e4%b8%80%e3%83%aa%e3%83%bc%e3%82%b8%e3%83%a7%e3%83%b3%e3%81%ae%e8%a4%87%e6%95%b0%20GKE%20%e3%82%af%e3%83%a9%e3%82%b9%e3%82%bf%e3%81%a8%20Anthos%20Service%20Mesh%20%e3%81%a7%e3%83%9e%e3%83%ab%e3%83%81%e3%82%af%e3%83%a9%e3%82%b9%e3%82%bf%e3%83%a1%e3%83%83%e3%82%b7%e3%83%a5%e7%92%b0%e5%a2%83%e3%82%92%e6%a7%8b%e7%af%89%e3%81%97%e3%81%a6%e3%81%bf%e3%81%9f%20-%20https%3a%2f%2fchacco38.github.io%2fposts%2f2021%2f12%2fgcp-multi-asm-cluster%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 単一リージョンの複数 GKE クラスタと Anthos Service Mesh でマルチクラスタメッシュ環境を構築してみた on telegram" href="https://telegram.me/share/url?text=%e5%8d%98%e4%b8%80%e3%83%aa%e3%83%bc%e3%82%b8%e3%83%a7%e3%83%b3%e3%81%ae%e8%a4%87%e6%95%b0%20GKE%20%e3%82%af%e3%83%a9%e3%82%b9%e3%82%bf%e3%81%a8%20Anthos%20Service%20Mesh%20%e3%81%a7%e3%83%9e%e3%83%ab%e3%83%81%e3%82%af%e3%83%a9%e3%82%b9%e3%82%bf%e3%83%a1%e3%83%83%e3%82%b7%e3%83%a5%e7%92%b0%e5%a2%83%e3%82%92%e6%a7%8b%e7%af%89%e3%81%97%e3%81%a6%e3%81%bf%e3%81%9f&url=https%3a%2f%2fchacco38.github.io%2fposts%2f2021%2f12%2fgcp-multi-asm-cluster%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>© 2022 Satoshi Matsuzawa</span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(t=>{const n=t.parentNode.parentNode,e=document.createElement("button");e.classList.add("copy-code"),e.innerText="copy";function s(){e.innerText="copied!",setTimeout(()=>{e.innerText="copy"},2e3)}e.addEventListener("click",o=>{if("clipboard"in navigator){navigator.clipboard.writeText(t.textContent),s();return}const e=document.createRange();e.selectNodeContents(t);const n=window.getSelection();n.removeAllRanges(),n.addRange(e);try{document.execCommand("copy"),s()}catch(e){}n.removeRange(e)}),n.classList.contains("highlight")?n.appendChild(e):n.parentNode.firstChild==n||(t.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?t.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(e):t.parentNode.appendChild(e))})</script></body></html>