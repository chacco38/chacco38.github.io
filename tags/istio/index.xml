<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Istio on クラウドCoEの何でも屋</title><link>https://chacco38.github.io/tags/istio/</link><description>Recent content in Istio on クラウドCoEの何でも屋</description><generator>Hugo -- gohugo.io</generator><language>ja-jp</language><copyright>&amp;copy; 2022 Satoshi Matsuzawa</copyright><lastBuildDate>Mon, 14 Feb 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://chacco38.github.io/tags/istio/index.xml" rel="self" type="application/rss+xml"/><item><title>Terraformを使ってGKE+ASMのマルチクラスタメッシュ環境を構築してみた</title><link>https://chacco38.github.io/posts/2022/02/gcp-deploy-asm-with-terraform/</link><pubDate>Mon, 14 Feb 2022 00:00:00 +0000</pubDate><guid>https://chacco38.github.io/posts/2022/02/gcp-deploy-asm-with-terraform/</guid><description>はじめに みなさん、こんにちは。以前に「複数リージョンのGKEクラスタとAnthos Service Meshでマルチクラスタメッシュ環境を構築してみた」という記事を書いたのですが、今回はその環境をTerraformを使って構築してみました。もしこれから「ASM環境をTerraformで」と検討している方は参考にしてみてはいかがでしょうか。
とはいえ、本記事の執筆時点(2022年1月末)ではTerraform公式モジュールがASMのv1.11以降に対応しておらず正直使いモノにならなかったこともあり、やや苦しい実装になってしまっています。素直にASMの導入以降はTerraform以外を使うのが良いかと思いますが、あくまで本記事はご参考ということでその点ご承知おきいただけると幸いです。
構築するシステムについて 次の図に示すように限定公開クラスを有効化した複数リージョンのGKEクラスタに対してAnthos Service Mesh(マネージドコントロールプレーン)を導入した環境となっています。なお、アプリケーションのコンテナについてはインフラとは異なるリポジトリで管理するのが一般的かと思うので今回は除外しています。
Terraformのサンプルコードを書いてみた それでは今回作成したTerraformのサンプルコードを紹介していきたいと思います。まずはディレクトリ構造ですが、今回はenvironmentsディレクトリ配下へ環境ごとにサブディレクトリを作成し、Workspaceは使わずに別ファイルとして管理する形を想定した作りにしてます。
ディレクトリ構成 . |-- environments | `-- poc | |-- backend.tf | |-- main.tf | `-- variables.tf `-- modules |-- networks | |-- main.tf | |-- variables.tf | `-- outputs.tf |-- gke | |-- main.tf | |-- variables.tf | `-- outputs.tf `-- asm |-- main.tf |-- variables.tf |-- scripts | |-- install.</description></item><item><title>GKE クラスタ作成時のオプションで Anthos Service Mesh を有効化できるようになりました</title><link>https://chacco38.github.io/posts/2021/12/gcp-new-asm-installation-options/</link><pubDate>Thu, 16 Dec 2021 00:00:00 +0000</pubDate><guid>https://chacco38.github.io/posts/2021/12/gcp-new-asm-installation-options/</guid><description>はじめに みなさん、こんにちは。今回はタイトルに掲げたとおり、最近の更新で Google Cloud コンソール(GUI)から Google Kubernetes Engine(GKE) Standard クラスタを作成する際に、次のようなすてきなオプションがプレビュー機能として追加されました。今回はこのオプションを使ってどのような構成が作られるのか実験したので共有したいと思います。
いきなりですが、結論です！ In-cluster とマネージドコントロールプレーンのどちらで構築される？ 答え、マネージドコントロールプレーンにて構築されます。現時点でこの設定を変更することはできません。
Anthos Service Mesh のバージョンは？ 答え、GKE でリリースチャンネルを採用した場合は GKE と同じチャンネルになります。GKE で静的リリースを採用した場合は Reguler チャンネルとなります。現時点でこの設定を変更することはできません。
カスタム CA を扱うことはできるか？ 答え、扱えません。マネージドコントロールプレーンでの導入となるため、カスタム CA を扱うことができる Istio CA を選択することはできません。
限定クラスタにした場合は別途 15017/TCP を許可する必要があるか？ 答え、不要です。ルールを追加しなくてもサイドカー自動インジェクションは問題なく動きます。
Ingress ゲートウェイはデフォルトで作られるか？ 答え、Ingress ゲートウェイはデフォルトでは作られません。別途ユーザにてデプロイする必要があります。
終わりに 今回は GKE クラスタ作成時の Anthos Service Mesh 有効化オプションの実験結果の共有でしたがいかがだったでしょうか。
GKE と Anthos Service Mesh で採用するリリースチャンネルを変えたい、カスタム CA を使いたいといったケースでは従来どおり CLI を利用する必要がありますが、これらの要件がなければ GUI からポチポチするだけでとっても簡単に環境を作れるようになりそうですね。
warn 2021 年 12 月時点ではGUI の Anthos Service Mesh 有効化オプションはプレビュー段階であり、今回紹介した挙動から変わる可能性がありますのでご注意ください。 {</description></item><item><title>単一リージョンの複数 GKE クラスタと Anthos Service Mesh でマルチクラスタメッシュ環境を構築してみた</title><link>https://chacco38.github.io/posts/2021/12/gcp-multi-asm-cluster/</link><pubDate>Thu, 09 Dec 2021 00:00:00 +0000</pubDate><guid>https://chacco38.github.io/posts/2021/12/gcp-multi-asm-cluster/</guid><description>はじめに みなさん、こんにちは。今回は単一リージョンに展開した複数 GKE クラスタを単一の Anthos Service Mesh 環境に追加し、GKE クラスタ間で負荷分散を行う方法についてご紹介していきたいと思います。
複数 GKE クラスタでマルチクラスタメッシュを構築することにより、片方の GKE クラスタを先にバージョンアップし、サービスメッシュのトラフィック制御を使ってバージョンアップしたクラスタ側に少量のトラフィックを流して問題がないことを確認しながら段階的に比重をあげていく、といった「基盤部分も含めたカナリアリリース」のユースケースも容易に実現できるようになる見込みです。
もちろん公式ドキュメントにもマルチクラスタメッシュの構築に関する記載はあるのですが、単にクラスタ間で分散されたことを確認しただけで終わっており、ルーティングの設定やメッシュの外からの通信に関する記載はなかったため、今回はここら辺も含めて一気通貫でご紹介したいと思います。もしこれから Anthos Service Mesh 環境の利用を検討している方は参考にしてみてはいかがでしょうか。
構築するシステムについて 次の図に示すように限定公開クラスタおよび承認済みネットワーク機能を有効化した単一リージョンの複数 GKE クラスタに対して Anthos Service Mesh (マネージドコントロールプレーン)を導入し、サービスメッシュ上でサンプルアプリケーションを動かしていきたいと思います。なお、今回の例では GKE、Anthos Service Mesh のいずれのリリースチャンネルについても安定性重視の Stable チャンネルを採用しています。
それでは構築していきましょう 公式ドキュメントを参考にしつつ、公式ドキュメントに書かれていない部分を補足しながら構築をしていきたいと思います。
https://cloud.google.com/service-mesh/docs/unified-install/gke-install-multi-cluster
Step1. VPC ネットワークの作成 まずは GKE ノードを配置する VPC ネットワークおよび東京リージョンにサブネットを作成します。今回の例では GKE ノードからプライベートネットワーク経由で Artifact Registry などの他のマネージドサービスへアクセスできるように限定公開の Google アクセスをオンにしています。
VPCネットワークの作成 # 環境変数の設定 export NETWORK=&amp;#34;matt-vpc&amp;#34; export SUBNET=&amp;#34;matt-private-vm&amp;#34; export LOCATION=&amp;#34;asia-northeast1&amp;#34; export IP_RANGE=&amp;#34;172.16.0.0/16&amp;#34; # VPC ネットワークの作成 gcloud compute networks create ${NETWORK} --subnet-mode=custom # サブネットの作成 gcloud compute networks subnets create ${SUBNET} \ --network=${NETWORK} --range=${IP_RANGE} --region=${LOCATION} \ --enable-private-ip-google-access プライベートネットワーク経由でインターネット上の Docker Hub などへ接続できるよう Cloud NAT も作成しておきます。</description></item><item><title>複数リージョンの GKE クラスタと Anthos Service Mesh でマルチクラスタメッシュ環境を構築してみた</title><link>https://chacco38.github.io/posts/2021/12/gcp-multi-region-asm-cluster/</link><pubDate>Thu, 09 Dec 2021 00:00:00 +0000</pubDate><guid>https://chacco38.github.io/posts/2021/12/gcp-multi-region-asm-cluster/</guid><description>はじめに みなさん、こんにちは。今回は複数のリージョンに展開する各 GKE クラスタを単一の Anthos Service Mesh 環境に追加し、GKE クラスタ間で負荷分散を行う方法についてご紹介していきたいと思います。
複数リージョンの GKE クラスタでマルチクラスタメッシュを構築することにより、予期しない大規模災害の発生にも耐えうる高い可用性と回復力の実現、エンドユーザからより近い位置への振り分けによるレイテンシの改善といったことが期待できるようになる見込みです。
もちろん公式ドキュメントにもマルチクラスタメッシュの構築に関する記載はあるのですが、単にクラスタ間で分散されたことを確認しただけで終わっており、ローカリティを意識したルーティングの設定やメッシュの外からの通信に関する記載はなかったため、今回はここら辺も含めて一気通貫でご紹介したいと思います。もしこれからリージョンをまたがった Anthos Service Mesh 環境の利用を検討している方は参考にしてみてはいかがでしょうか。
構築するシステムについて 次の図に示すように限定公開クラスタおよび承認済みネットワーク機能を有効化した複数リージョンの GKE クラスタに対して Anthos Service Mesh (マネージドコントロールプレーン)を導入しています。サービスメッシュ上ではサンプルアプリケーションを動かし、ローカリティを意識した負荷分散についても設定をしていきたいと思います。なお、今回の例では GKE、Anthos Service Mesh のいずれのリリースチャンネルについても安定性重視の Stable チャンネルを採用しています。
それでは構築していきましょう いつも通り公式ドキュメントを参考にしつつ、公式ドキュメントに書かれていない部分を補足しながら構築をしていきたいと思います。
https://cloud.google.com/service-mesh/docs/unified-install/gke-install-multi-cluster
Step1. VPC ネットワークの作成 まずは GKE ノードを配置する VPC ネットワークおよび東京リージョンと大阪リージョンにサブネットを作成します。今回の例では GKE ノードからプライベートネットワーク経由で Artifact Registry などの他のマネージドサービスへアクセスできるように限定公開の Google アクセスをオンにしています。
VPCネットワークの作成 # 環境変数の設定 export NETWORK=&amp;#34;matt-vpc&amp;#34; export SUBNET=&amp;#34;matt-private-vm&amp;#34; export LOCATION_1=&amp;#34;asia-northeast1&amp;#34; export LOCATION_2=&amp;#34;asia-northeast2&amp;#34; export IP_RANGE_1=&amp;#34;172.16.0.0/16&amp;#34; export IP_RANGE_2=&amp;#34;172.24.0.0/16&amp;#34; # VPC ネットワークの作成 gcloud compute networks create ${NETWORK} --subnet-mode=custom # サブネットの作成 (東京リージョン) gcloud compute networks subnets create ${SUBNET} \ --network=${NETWORK} --range=${IP_RANGE_1} --region=${LOCATION_1} \ --enable-private-ip-google-access # サブネットの作成 (大阪リージョン) gcloud compute networks subnets create ${SUBNET} \ --network=${NETWORK} --range=${IP_RANGE_2} --region=${LOCATION_2} \ --enable-private-ip-google-access プライベートネットワーク経由でインターネット上の Docker Hub などへ接続できるよう Cloud NAT も作成しておきます。</description></item><item><title>GKE Autopilot と Anthos Service Mesh を使ってフルマネージドなサービスメッシュ環境を構築してみた</title><link>https://chacco38.github.io/posts/2021/12/gcp-asm-with-gke-autopilot/</link><pubDate>Wed, 01 Dec 2021 00:00:00 +0000</pubDate><guid>https://chacco38.github.io/posts/2021/12/gcp-asm-with-gke-autopilot/</guid><description>はじめに みなさん、こんにちは。今回は Google Cloud が提供するマネージドサービスメッシュサービスの Anthos Service Mesh に関するお話です。
Anthos Service Mesh はここ半年で「マネージドコントロールプレーン機能の一般公開」、「マネージドデータプレーン機能のプレビュー公開」と Google マネージドの範囲を徐々に広げてきましたが、2021 年 11 月 19 日の更新でプレビュー段階ではありますが「Google Kubernetes Engine(GKE) Autopilot 上でも Anthos Service Mesh を利用できる」ようになりました。
今回はそんなプレビュー公開されたばかりの GKE Autopilot と Anthos Service Mesh(ASM) を使った Kubernetes 部分も含めてフルマネージドなサービスメッシュ環境を構築していきたいと思います。
構築するシステムについて 次の図に示すように限定公開クラスタおよび承認済みネットワーク機能を有効化した GKE Autopilot クラスタに対して Anthos Service Mesh を導入し、サービスメッシュ上でサンプルアプリケーションを動かしていきたいと思います。
それでは構築していきましょう いつも通り公式ドキュメントを参考にしつつ、公式ドキュメントに書かれていない部分を補足しながら構築をしていきたいと思います。
https://cloud.google.com/service-mesh/docs/unified-install/managed-asmcli-experimental
Step1. VPC ネットワークの作成 まずは GKE ノードを配置する VPC ネットワークおよび東京リージョンにサブネットを作成します。今回の例では GKE ノードからプライベートネットワーク経由で Artifact Registry などの他のマネージドサービスへアクセスできるように限定公開の Google アクセスをオンにしています。
プライベートネットワークからインターネット上の Docker Hub などへ接続できるよう Cloud NAT リソースも作成しておきたいと思います。</description></item></channel></rss>